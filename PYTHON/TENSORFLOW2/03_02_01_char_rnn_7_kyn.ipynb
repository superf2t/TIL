{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_02_01_char_rnn_7_kyn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KwonYN/TIL/blob/master/PYTHON/TENSORFLOW2/03_02_01_char_rnn_7_kyn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUbrsmxWf04y",
        "colab_type": "text"
      },
      "source": [
        "# **실습 3-2 : Char-RNN**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZQKizrb-Y1er"
      },
      "source": [
        "## **Import Module**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0trJmd6DjqBZ",
        "outputId": "0bfbfd62-17e9-423c-bcae-59d2cf18c53f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOiaPQ3xgJQC",
        "colab_type": "text"
      },
      "source": [
        "## **DataSet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD28IHuegUxp",
        "colab_type": "text"
      },
      "source": [
        "### 학습할 문장 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC8AS287Hz-9",
        "colab_type": "code",
        "outputId": "fd8b1726-adf2-4932-faf8-3fe9203f3e60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# 학습할 문장\n",
        "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
        "            \"collect wood and don't assign them tasks and work, but rather \"\n",
        "            \"teach them to long for the endless immensity of the sea.\" )\n",
        "print (\"FOLLOWING IS OUR TRAINING SEQUENCE:\")\n",
        "print (sentence)\n",
        "print (\"Length of 'test sentence' is %s\" %len(sentence))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOLLOWING IS OUR TRAINING SEQUENCE:\n",
            "if you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
            "Length of 'test sentence' is 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0oDy0CggOEm",
        "colab_type": "text"
      },
      "source": [
        "### 입력 문자열과 타겟 문자 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7d2RtBMDI6a",
        "colab_type": "code",
        "outputId": "29760699-b5f9-4705-eb4a-3cea158f7152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "# make charater dictionary \n",
        "char_set = list(set(sentence))\n",
        "char_dic = {w: i for i, w in enumerate(char_set)}\n",
        "print (\"CHARACTERS :\", len(char_set))\n",
        "print (\"ㄴ\", char_set)\n",
        "print (\"DICTIONARY :\", len(char_dic))\n",
        "print ('ㄴ', char_dic)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CHARACTERS : 25\n",
            "ㄴ [',', 'b', 'y', ' ', 'c', 'h', 'u', 'd', 'r', 'i', 'w', 'o', '.', \"'\", 'a', 's', 'n', 'g', 't', 'f', 'l', 'm', 'k', 'e', 'p']\n",
            "DICTIONARY : 25\n",
            "ㄴ {',': 0, 'b': 1, 'y': 2, ' ': 3, 'c': 4, 'h': 5, 'u': 6, 'd': 7, 'r': 8, 'i': 9, 'w': 10, 'o': 11, '.': 12, \"'\": 13, 'a': 14, 's': 15, 'n': 16, 'g': 17, 't': 18, 'f': 19, 'l': 20, 'm': 21, 'k': 22, 'e': 23, 'p': 24}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LXjO9txq9nR",
        "colab_type": "code",
        "outputId": "3f84b5b8-edc0-4870-f47d-c8280fa9ca0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "data_dim    = len(char_set) # train data X:input\n",
        "num_classes = len(char_set) # trian data Y:target\n",
        "sequence_length = 10        # any arbitrary number\n",
        "print ('data_dim : %d' %data_dim)\n",
        "print ('num_classes : %d' %num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_dim : 25\n",
            "num_classes : 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGnO0NygDI6M",
        "colab_type": "code",
        "outputId": "f3b9d4c9-ef50-4f04-d688-f8da5f7c13d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "dataX = []  # input sequence list\n",
        "dataY = []  # target sequence list \n",
        "\n",
        "# we will make 170 sequences \n",
        "for i in range(0, len(sentence) - sequence_length):\n",
        "    # 10 characters = 1 training sequence\n",
        "    x_str = sentence[i : i+sequence_length]\n",
        "    y_str = sentence[i+1 : i+sequence_length+1]\n",
        "    # convert x, y str to index(int)\n",
        "    x_idx = [char_dic[c] for c in x_str] \n",
        "    y_idx = [char_dic[c] for c in y_str] \n",
        "    # append to dataset list\n",
        "    dataX.append(x_idx)\n",
        "    dataY.append(y_idx)\n",
        "\n",
        "    # monitoring\n",
        "    if i<5:\n",
        "        print (\"[%3d/%3d] [%s]=>[%s]\" % (i, len(sentence), x_str, y_str))\n",
        "        print (\"%s%s=>%s\" % (' '*10, x_idx, y_idx))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0/180] [if you wan]=>[f you want]\n",
            "          [9, 19, 3, 2, 11, 6, 3, 10, 14, 16]=>[19, 3, 2, 11, 6, 3, 10, 14, 16, 18]\n",
            "[  1/180] [f you want]=>[ you want ]\n",
            "          [19, 3, 2, 11, 6, 3, 10, 14, 16, 18]=>[3, 2, 11, 6, 3, 10, 14, 16, 18, 3]\n",
            "[  2/180] [ you want ]=>[you want t]\n",
            "          [3, 2, 11, 6, 3, 10, 14, 16, 18, 3]=>[2, 11, 6, 3, 10, 14, 16, 18, 3, 18]\n",
            "[  3/180] [you want t]=>[ou want to]\n",
            "          [2, 11, 6, 3, 10, 14, 16, 18, 3, 18]=>[11, 6, 3, 10, 14, 16, 18, 3, 18, 11]\n",
            "[  4/180] [ou want to]=>[u want to ]\n",
            "          [11, 6, 3, 10, 14, 16, 18, 3, 18, 11]=>[6, 3, 10, 14, 16, 18, 3, 18, 11, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59y_7OfhvMpY",
        "colab_type": "text"
      },
      "source": [
        "### 입력문자 list를 3-dim로, 타겟문자 list를 2-dim로 변환  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obs8_hpYv1gd",
        "colab_type": "code",
        "outputId": "b83511dc-316f-4780-bf81-76d0e90094da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "# input tensor 생성 \n",
        "X = np.array(dataX)                                      # ndarray(170,10)<-[170,10]\n",
        "# convert list sequence to 3dim array(one-hot coding)\n",
        "sequences = [tf.keras.utils.to_categorical(\n",
        "                 x, num_classes = data_dim) for x in X]  # list[170,10,25]\n",
        "X = np.array(sequences)                                  # ndarray(170,10,25)\n",
        "print(\"shape of X :\", X.shape)\n",
        "\n",
        "# Target tensor 생성\n",
        "#y = np.array(dataY)[:,-1]                                # ndarray(170,)<-[170,10]\n",
        "y = np.array(dataY)                                       # ndarray(170,10)<-[170,10]\n",
        "print(\"shape of y :\", y.shape)\n",
        "\n",
        "# convert the vector to 2-dim \n",
        "y = tf.keras.utils.to_categorical(\n",
        "                  y, num_classes = data_dim)             # (170,25) -> (170,10,25)\n",
        "\n",
        "print (\"shape of y :\", y.shape) # (170,10,25)\n",
        "#print (y[0])    # t -> one-hot ,  (if you wan't')\n",
        "print (y[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of X : (170, 10, 25)\n",
            "shape of y : (170, 10)\n",
            "shape of y : (170, 10, 25)\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "  0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY3zfzjlgbYj",
        "colab_type": "text"
      },
      "source": [
        "## **Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUqUyRtngdUC",
        "colab_type": "text"
      },
      "source": [
        "### Define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCAvqXiiDI6X",
        "colab_type": "code",
        "outputId": "edadd19f-f6be-4bc7-b889-c32f6e29cf98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# Sequenctial model define: LSTM + Dense\n",
        "hidden_dim = 75 #150\n",
        "model=tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(hidden_dim,\n",
        "          input_shape=(sequence_length,num_classes),\n",
        "          return_sequences=True)) # (bs,10,hidden_dim)<-(bs,hidden_dim)\n",
        "#model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(data_dim, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 10, 75)            30300     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10, 25)            1900      \n",
            "=================================================================\n",
            "Total params: 32,200\n",
            "Trainable params: 32,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zMat0-hSzeq_"
      },
      "source": [
        "### Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3VyAq7gzkuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss ='categorical_crossentropy', # one-hot coding\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9BG8hNUgo0n",
        "colab_type": "text"
      },
      "source": [
        "### Fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KbIreYLd6gj",
        "colab_type": "text"
      },
      "source": [
        "Epoch 1000/1000   \n",
        "170/170 [==============================] - 0s 235us/sample - loss: 0.0012 - accuracy: 1.0000    \n",
        "CPU times: user 48.3 s, sys: 6.54 s, total: 54.8 s    \n",
        "Wall time: 47.8 s (@Notebook Setting/GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_idMKYwKVqX",
        "colab_type": "code",
        "outputId": "6294fa77-079e-4631-9a19-ea8844ef9f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "model.fit(X,            # X.shape : (170, 10, 25)\n",
        "          y,            # y.shape : (170, 10, 25)\n",
        "          epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 170 samples\n",
            "Epoch 1/100\n",
            "170/170 [==============================] - 5s 29ms/sample - loss: 3.2095 - accuracy: 0.0582\n",
            "Epoch 2/100\n",
            "170/170 [==============================] - 0s 202us/sample - loss: 3.1749 - accuracy: 0.1771\n",
            "Epoch 3/100\n",
            "170/170 [==============================] - 0s 195us/sample - loss: 3.1332 - accuracy: 0.1988\n",
            "Epoch 4/100\n",
            "170/170 [==============================] - 0s 195us/sample - loss: 3.0725 - accuracy: 0.1959\n",
            "Epoch 5/100\n",
            "170/170 [==============================] - 0s 193us/sample - loss: 2.9893 - accuracy: 0.1947\n",
            "Epoch 6/100\n",
            "170/170 [==============================] - 0s 198us/sample - loss: 2.9544 - accuracy: 0.1965\n",
            "Epoch 7/100\n",
            "170/170 [==============================] - 0s 197us/sample - loss: 2.9198 - accuracy: 0.1971\n",
            "Epoch 8/100\n",
            "170/170 [==============================] - 0s 193us/sample - loss: 2.8970 - accuracy: 0.1982\n",
            "Epoch 9/100\n",
            "170/170 [==============================] - 0s 202us/sample - loss: 2.8739 - accuracy: 0.2012\n",
            "Epoch 10/100\n",
            "170/170 [==============================] - 0s 190us/sample - loss: 2.8513 - accuracy: 0.2024\n",
            "Epoch 11/100\n",
            "170/170 [==============================] - 0s 248us/sample - loss: 2.8280 - accuracy: 0.2029\n",
            "Epoch 12/100\n",
            "170/170 [==============================] - 0s 209us/sample - loss: 2.8038 - accuracy: 0.2035\n",
            "Epoch 13/100\n",
            "170/170 [==============================] - 0s 213us/sample - loss: 2.7765 - accuracy: 0.2041\n",
            "Epoch 14/100\n",
            "170/170 [==============================] - 0s 189us/sample - loss: 2.7486 - accuracy: 0.2053\n",
            "Epoch 15/100\n",
            "170/170 [==============================] - 0s 223us/sample - loss: 2.7155 - accuracy: 0.2112\n",
            "Epoch 16/100\n",
            "170/170 [==============================] - 0s 192us/sample - loss: 2.6824 - accuracy: 0.2247\n",
            "Epoch 17/100\n",
            "170/170 [==============================] - 0s 217us/sample - loss: 2.6483 - accuracy: 0.2353\n",
            "Epoch 18/100\n",
            "170/170 [==============================] - 0s 195us/sample - loss: 2.6156 - accuracy: 0.2512\n",
            "Epoch 19/100\n",
            "170/170 [==============================] - 0s 222us/sample - loss: 2.5741 - accuracy: 0.2594\n",
            "Epoch 20/100\n",
            "170/170 [==============================] - 0s 192us/sample - loss: 2.5323 - accuracy: 0.2765\n",
            "Epoch 21/100\n",
            "170/170 [==============================] - 0s 215us/sample - loss: 2.4896 - accuracy: 0.2871\n",
            "Epoch 22/100\n",
            "170/170 [==============================] - 0s 239us/sample - loss: 2.4446 - accuracy: 0.2924\n",
            "Epoch 23/100\n",
            "170/170 [==============================] - 0s 197us/sample - loss: 2.4039 - accuracy: 0.3100\n",
            "Epoch 24/100\n",
            "170/170 [==============================] - 0s 197us/sample - loss: 2.3562 - accuracy: 0.3382\n",
            "Epoch 25/100\n",
            "170/170 [==============================] - 0s 190us/sample - loss: 2.3051 - accuracy: 0.3459\n",
            "Epoch 26/100\n",
            "170/170 [==============================] - 0s 198us/sample - loss: 2.2541 - accuracy: 0.3776\n",
            "Epoch 27/100\n",
            "170/170 [==============================] - 0s 207us/sample - loss: 2.2072 - accuracy: 0.3906\n",
            "Epoch 28/100\n",
            "170/170 [==============================] - 0s 243us/sample - loss: 2.1541 - accuracy: 0.4065\n",
            "Epoch 29/100\n",
            "170/170 [==============================] - 0s 195us/sample - loss: 2.1031 - accuracy: 0.4306\n",
            "Epoch 30/100\n",
            "170/170 [==============================] - 0s 191us/sample - loss: 2.0555 - accuracy: 0.4376\n",
            "Epoch 31/100\n",
            "170/170 [==============================] - 0s 181us/sample - loss: 2.0071 - accuracy: 0.4541\n",
            "Epoch 32/100\n",
            "170/170 [==============================] - 0s 198us/sample - loss: 1.9577 - accuracy: 0.4724\n",
            "Epoch 33/100\n",
            "170/170 [==============================] - 0s 211us/sample - loss: 1.9118 - accuracy: 0.4818\n",
            "Epoch 34/100\n",
            "170/170 [==============================] - 0s 196us/sample - loss: 1.8612 - accuracy: 0.4859\n",
            "Epoch 35/100\n",
            "170/170 [==============================] - 0s 200us/sample - loss: 1.8176 - accuracy: 0.4965\n",
            "Epoch 36/100\n",
            "170/170 [==============================] - 0s 200us/sample - loss: 1.7751 - accuracy: 0.5229\n",
            "Epoch 37/100\n",
            "170/170 [==============================] - 0s 217us/sample - loss: 1.7285 - accuracy: 0.5224\n",
            "Epoch 38/100\n",
            "170/170 [==============================] - 0s 203us/sample - loss: 1.6897 - accuracy: 0.5400\n",
            "Epoch 39/100\n",
            "170/170 [==============================] - 0s 248us/sample - loss: 1.6586 - accuracy: 0.5500\n",
            "Epoch 40/100\n",
            "170/170 [==============================] - 0s 188us/sample - loss: 1.6160 - accuracy: 0.5676\n",
            "Epoch 41/100\n",
            "170/170 [==============================] - 0s 196us/sample - loss: 1.5795 - accuracy: 0.5753\n",
            "Epoch 42/100\n",
            "170/170 [==============================] - 0s 207us/sample - loss: 1.5414 - accuracy: 0.5859\n",
            "Epoch 43/100\n",
            "170/170 [==============================] - 0s 189us/sample - loss: 1.5044 - accuracy: 0.6024\n",
            "Epoch 44/100\n",
            "170/170 [==============================] - 0s 198us/sample - loss: 1.4710 - accuracy: 0.6088\n",
            "Epoch 45/100\n",
            "170/170 [==============================] - 0s 230us/sample - loss: 1.4358 - accuracy: 0.6218\n",
            "Epoch 46/100\n",
            "170/170 [==============================] - 0s 206us/sample - loss: 1.4042 - accuracy: 0.6424\n",
            "Epoch 47/100\n",
            "170/170 [==============================] - 0s 189us/sample - loss: 1.3747 - accuracy: 0.6424\n",
            "Epoch 48/100\n",
            "170/170 [==============================] - 0s 198us/sample - loss: 1.3423 - accuracy: 0.6565\n",
            "Epoch 49/100\n",
            "170/170 [==============================] - 0s 201us/sample - loss: 1.3130 - accuracy: 0.6600\n",
            "Epoch 50/100\n",
            "170/170 [==============================] - 0s 190us/sample - loss: 1.2835 - accuracy: 0.6765\n",
            "Epoch 51/100\n",
            "170/170 [==============================] - 0s 190us/sample - loss: 1.2565 - accuracy: 0.6865\n",
            "Epoch 52/100\n",
            "170/170 [==============================] - 0s 205us/sample - loss: 1.2297 - accuracy: 0.6918\n",
            "Epoch 53/100\n",
            "170/170 [==============================] - 0s 191us/sample - loss: 1.2038 - accuracy: 0.7047\n",
            "Epoch 54/100\n",
            "170/170 [==============================] - 0s 200us/sample - loss: 1.1774 - accuracy: 0.7112\n",
            "Epoch 55/100\n",
            "170/170 [==============================] - 0s 195us/sample - loss: 1.1535 - accuracy: 0.7165\n",
            "Epoch 56/100\n",
            "170/170 [==============================] - 0s 218us/sample - loss: 1.1316 - accuracy: 0.7229\n",
            "Epoch 57/100\n",
            "170/170 [==============================] - 0s 208us/sample - loss: 1.1063 - accuracy: 0.7288\n",
            "Epoch 58/100\n",
            "170/170 [==============================] - 0s 197us/sample - loss: 1.0819 - accuracy: 0.7418\n",
            "Epoch 59/100\n",
            "170/170 [==============================] - 0s 198us/sample - loss: 1.0593 - accuracy: 0.7465\n",
            "Epoch 60/100\n",
            "170/170 [==============================] - 0s 190us/sample - loss: 1.0394 - accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "170/170 [==============================] - 0s 207us/sample - loss: 1.0195 - accuracy: 0.7506\n",
            "Epoch 62/100\n",
            "170/170 [==============================] - 0s 188us/sample - loss: 0.9985 - accuracy: 0.7565\n",
            "Epoch 63/100\n",
            "170/170 [==============================] - 0s 188us/sample - loss: 0.9775 - accuracy: 0.7612\n",
            "Epoch 64/100\n",
            "170/170 [==============================] - 0s 195us/sample - loss: 0.9579 - accuracy: 0.7676\n",
            "Epoch 65/100\n",
            "170/170 [==============================] - 0s 205us/sample - loss: 0.9407 - accuracy: 0.7729\n",
            "Epoch 66/100\n",
            "170/170 [==============================] - 0s 201us/sample - loss: 0.9243 - accuracy: 0.7741\n",
            "Epoch 67/100\n",
            "170/170 [==============================] - 0s 199us/sample - loss: 0.9068 - accuracy: 0.7806\n",
            "Epoch 68/100\n",
            "170/170 [==============================] - 0s 300us/sample - loss: 0.8898 - accuracy: 0.7835\n",
            "Epoch 69/100\n",
            "170/170 [==============================] - 0s 242us/sample - loss: 0.8741 - accuracy: 0.7876\n",
            "Epoch 70/100\n",
            "170/170 [==============================] - 0s 246us/sample - loss: 0.8580 - accuracy: 0.7894\n",
            "Epoch 71/100\n",
            "170/170 [==============================] - 0s 207us/sample - loss: 0.8428 - accuracy: 0.7947\n",
            "Epoch 72/100\n",
            "170/170 [==============================] - 0s 188us/sample - loss: 0.8281 - accuracy: 0.7929\n",
            "Epoch 73/100\n",
            "170/170 [==============================] - 0s 201us/sample - loss: 0.8142 - accuracy: 0.7959\n",
            "Epoch 74/100\n",
            "170/170 [==============================] - 0s 201us/sample - loss: 0.8005 - accuracy: 0.8000\n",
            "Epoch 75/100\n",
            "170/170 [==============================] - 0s 233us/sample - loss: 0.7883 - accuracy: 0.8000\n",
            "Epoch 76/100\n",
            "170/170 [==============================] - 0s 225us/sample - loss: 0.7749 - accuracy: 0.8024\n",
            "Epoch 77/100\n",
            "170/170 [==============================] - 0s 202us/sample - loss: 0.7623 - accuracy: 0.8035\n",
            "Epoch 78/100\n",
            "170/170 [==============================] - 0s 243us/sample - loss: 0.7500 - accuracy: 0.8071\n",
            "Epoch 79/100\n",
            "170/170 [==============================] - 0s 249us/sample - loss: 0.7383 - accuracy: 0.8100\n",
            "Epoch 80/100\n",
            "170/170 [==============================] - 0s 194us/sample - loss: 0.7269 - accuracy: 0.8106\n",
            "Epoch 81/100\n",
            "170/170 [==============================] - 0s 242us/sample - loss: 0.7161 - accuracy: 0.8135\n",
            "Epoch 82/100\n",
            "170/170 [==============================] - 0s 232us/sample - loss: 0.7060 - accuracy: 0.8176\n",
            "Epoch 83/100\n",
            "170/170 [==============================] - 0s 230us/sample - loss: 0.6961 - accuracy: 0.8194\n",
            "Epoch 84/100\n",
            "170/170 [==============================] - 0s 218us/sample - loss: 0.6868 - accuracy: 0.8224\n",
            "Epoch 85/100\n",
            "170/170 [==============================] - 0s 255us/sample - loss: 0.6781 - accuracy: 0.8224\n",
            "Epoch 86/100\n",
            "170/170 [==============================] - 0s 218us/sample - loss: 0.6684 - accuracy: 0.8229\n",
            "Epoch 87/100\n",
            "170/170 [==============================] - 0s 240us/sample - loss: 0.6591 - accuracy: 0.8265\n",
            "Epoch 88/100\n",
            "170/170 [==============================] - 0s 206us/sample - loss: 0.6506 - accuracy: 0.8300\n",
            "Epoch 89/100\n",
            "170/170 [==============================] - 0s 221us/sample - loss: 0.6424 - accuracy: 0.8312\n",
            "Epoch 90/100\n",
            "170/170 [==============================] - 0s 207us/sample - loss: 0.6338 - accuracy: 0.8341\n",
            "Epoch 91/100\n",
            "170/170 [==============================] - 0s 205us/sample - loss: 0.6268 - accuracy: 0.8341\n",
            "Epoch 92/100\n",
            "170/170 [==============================] - 0s 186us/sample - loss: 0.6185 - accuracy: 0.8371\n",
            "Epoch 93/100\n",
            "170/170 [==============================] - 0s 202us/sample - loss: 0.6127 - accuracy: 0.8382\n",
            "Epoch 94/100\n",
            "170/170 [==============================] - 0s 257us/sample - loss: 0.6043 - accuracy: 0.8429\n",
            "Epoch 95/100\n",
            "170/170 [==============================] - 0s 230us/sample - loss: 0.5981 - accuracy: 0.8441\n",
            "Epoch 96/100\n",
            "170/170 [==============================] - 0s 192us/sample - loss: 0.5903 - accuracy: 0.8465\n",
            "Epoch 97/100\n",
            "170/170 [==============================] - 0s 182us/sample - loss: 0.5844 - accuracy: 0.8471\n",
            "Epoch 98/100\n",
            "170/170 [==============================] - 0s 205us/sample - loss: 0.5778 - accuracy: 0.8471\n",
            "Epoch 99/100\n",
            "170/170 [==============================] - 0s 209us/sample - loss: 0.5708 - accuracy: 0.8494\n",
            "Epoch 100/100\n",
            "170/170 [==============================] - 0s 193us/sample - loss: 0.5654 - accuracy: 0.8518\n",
            "CPU times: user 6.95 s, sys: 874 ms, total: 7.82 s\n",
            "Wall time: 8.54 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f52020a77b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7Bf90ATg98K",
        "colab_type": "text"
      },
      "source": [
        "## **Generate Text:** analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcGTERphhBNs",
        "colab_type": "text"
      },
      "source": [
        "### Related Module Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uBnrJJe0fgz",
        "colab_type": "text"
      },
      "source": [
        "### Define generate_seq function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFq9I4aCDI6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# generate a sequence of characters with a language model\n",
        "def generate_seq(model, char_dic, seq_length, seed_text, n_chars):\n",
        "\tin_text = seed_text\t\t\t\t\t\t\t\t\t# seed text + generated text\n",
        "\t# generate a fixed number of characters\n",
        "\tfor i in range(n_chars):\n",
        "\t\t# encode the characters as integers\n",
        "\t\tencoded = [char_dic[char] for char in in_text]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# one hot encode\n",
        "\t\tencoded = tf.keras.utils.to_categorical(encoded, num_classes=len(char_dic))\n",
        "\t\t#encoded = encoded.reshape(1, encoded.shape[0], encoded.shape[1])\n",
        "\t\t# predict character\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# reverse map integer to character\n",
        "\t\tfor char, index in char_dic.items():\n",
        "\t\t\tif index == yhat[0][-1]:\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += char\n",
        "\treturn in_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2_tIRa7h1PUA"
      },
      "source": [
        "### Generate a sequence of characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhgIpBwG06uc",
        "colab_type": "text"
      },
      "source": [
        "학습문장: if you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC3D8JPW1O0Y",
        "colab_type": "code",
        "outputId": "2bd0c428-eabd-4869-db36-41e80694f7cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "# test start of rhyme\n",
        "print('Trigger characters: \"want to bu \"\\nResult: \\n\"{}\"'.format( \n",
        "      generate_seq(model, char_dic, sequence_length, 'want to bu', 200)))\n",
        "# test mid-line\n",
        "print('\\nTrigger characters: \"collect wo\"\\nResult: \\n\"{}\"'.format(\n",
        "      generate_seq(model, char_dic, sequence_length, 'collect wo', 200)))\n",
        "# test mid-line\n",
        "print('\\nTrigger characters: \"rather tea\"\\nResult: \"{}\"'.format(\n",
        "      generate_seq(model, char_dic, sequence_length, 'rather tea', 200)))\n",
        "# test not in original\n",
        "print('\\nTrigger characters: \"aabbcr than\"\\nResult: \"{}\"'.format(\n",
        "      generate_seq(model, char_dic, sequence_length, 'aabbcr than', 200)))\n",
        "# test not in original\n",
        "print('\\nTrigger characters: \"hidoyi\"\\nResult: \"{}\"'.format(\n",
        "      generate_seq(model, char_dic, sequence_length, 'hidoyi', 200)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trigger characters: \"want to bu \"\n",
            "Result: \n",
            "\"want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the seasks and work, but rather teach them to\"\n",
            "\n",
            "Trigger characters: \"collect wo\"\n",
            "Result: \n",
            "\"collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the seasks and work, but rather teach them to long for the endless immensity of the seasks and work,\"\n",
            "\n",
            "Trigger characters: \"rather tea\"\n",
            "Result: \"rather teach them to long for the endless immensity of the seasks and work, but rather teach them to long for the endless immensity of the seasks and work, but rather teach them to long for the endless immensit\"\n",
            "\n",
            "Trigger characters: \"aabbcr than\"\n",
            "Result: \"aabbcr than them tasks and work, but rather teach them to long for the endless immensity of the seasks and work, but rather teach them to long for the endless immensity of the seasks and work, but rather teach t\"\n",
            "\n",
            "Trigger characters: \"hidoyi\"\n",
            "Result: \"hidoyif the seasks and work, but rather teach them to long for the endless immensity of the seasks and work, but rather teach them to long for the endless immensity of the seasks and work, but rather teach \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58HIiOvpuG3",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "040c3576-221f-49af-fd7c-e58378b1046a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "#@title\n",
        "print('\\nTrigger characters: \"aabbcr than\"\\nResult: \"{}\"'.format(\n",
        "      generate_seq(model, char_dic, sequence_length, 'ports', 200)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Trigger characters: \"aabbcr than\"\n",
            "Result: \"ports theenetter to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the seasks and work, but rather teach them to long for the endless immensit\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnaUZbi_hIHw",
        "colab_type": "text"
      },
      "source": [
        "## **실습과제**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07YM3eLIWxSY",
        "colab_type": "text"
      },
      "source": [
        "### 과제 1. 학습문장을 Keras Documents에서 2000자 정도 가져다 넣어서 실행해 보자('.'뒤에'\\n'도 넣어주자) \n",
        "#### -- accuracy가 적당한가 확인하자.\n",
        "#### -- 모델을 강화 하기 위해 `hidden_dim ='값을 150으로 높히고, \n",
        "#### -- `#`로 막혀 있는 `BatchNormalization()`을 동작시켜 보자\n",
        "#### -- `Trigger characters`를 다양하게 바꿔보자 \n",
        "#### -- 결과를 확인하고, 분석해 보자:\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2pE99BIbdbi",
        "colab_type": "code",
        "outputId": "6dc8dd7a-b5a9-4cb0-a103-a32a6dea5de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "new_sentence = \"\"\"When it comes to Donald Trump and Russia, everything is connected.\n",
        "That’s the most important lesson from the two big events that played out Monday on Capitol Hill — the House Judiciary Committee’s hearings on President Trump’s impeachment and the release of the report on the origins of the F.B.I.’s investigation into ties between the Trump campaign and the Russian government.\n",
        "One of these involved the 2016 election. The other involves the 2020 election. Both tell versions of the same story: Mr. Trump depends on, and welcomes, Russian interference to help him win the presidency. That was bad enough when he did it in 2016, openly calling for Russia to hack into his opponent’s emails — which Russians tried to do that same day. But he was only a candidate then. Now that Mr. Trump is president, he is wielding the immense powers of his office to achieve the same end.\n",
        "That is precisely the type of abuse of power that the founders were most concerned about when they created the impeachment power, and it’s why Democratic leaders in the House are pressing ahead with such urgency on their inquiry. They are trying to ensure that the 2020 election, now less than a year away, is not corrupted by the president of the United States, acting in league with a foreign power. 'The integrity of our next election is at stake,' said Representative Jerry Nadler, the chairman of the Judiciary Committee. “Nothing could be more urgent.”\n",
        "On Monday morning, lawyers for the Democrats on the House Judiciary and Intelligence committees presented the clearest and most comprehensive narrative yet of President Trump’s monthslong shakedown of the new Ukrainian president, Volodymyr Zelensky, for Mr. Trump’s personal political benefit. They explained in methodical detail how the president withheld a White House meeting and hundreds of millions of dollars in crucial, congressionally authorized military aid to Ukraine, all in an effort to get Mr. Zelensky to announce two investigations — one into Mr. Trump’s political rival, Joe Biden, and his son, Hunter, and another into Ukraine’s supposed interference in the 2016 election.\n",
        "Who would benefit from these announcements? Mr. Trump, who believes his re-election prospects are threatened most by Mr. Biden, and Vladimir Putin, the president of Russia, who has been working for years to make Ukraine the fall guy for his own interference in the 2016 election. Mr. Putin has not fooled serious people, like those in the American intelligence community who determined that his government alone was responsible for meddling on Mr. Trump’s behalf. But he has fooled Republicans in Congress, who have degraded themselves and their offices by faithfully parroting Mr. Putin’s propaganda in the mainstream press.\n",
        "House Republicans continued to do their best to obfuscate and misdirect, as they have done throughout the impeachment process. From the start of Monday’s hearing, they yelled and objected — an understandable strategy for people whose most honest defense of the president’s actions has been: 'Yeah, he did it. So what?' But this was not a performance for the history books; it was for the president himself, who registers only who is defending him and with how much fist-pounding rage.\n",
        "The upshot is that Republicans, who once claimed to be the party of patriots and national security devotees, are on the record as having no problem with an American president using hundreds of millions of taxpayer dollars in an effort to induce foreign leaders to interfere in an election on his behalf. (Unless that president were a Democrat, of course.)\n",
        "The emptiness of the Republicans’ case was exemplified in an interruption by Representative Mike Johnson of Louisiana, who stopped the morning’s proceedings after Barry Berke, the Judiciary Committee’s Democratic counsel, testified that President Trump had committed impeachable acts. 'The witness has used language which impugns the motives of the president and suggests he’s disloyal to his country, and those words should be stricken from the record and taken down,\\\" Mr. Johnson said. He was referring to a House rule that applies only to members of Congress, not witnesses. But consider the message he was sending: In the face of the most damning facts brought forward about a president in more than a generation, Mr. Johnson’s instinct was to say, in effect, How dare you speak the truth about our dear leader?\n",
        "Speaking the truth, or accepting it when they hear it, is a skill that has become increasingly foreign to Republicans. Which brings us to the other big news of the day: the release of the 434-page report by the Justice Department’s inspector general, Michael Horowitz, into the basis for the F.B.I.’s investigation of the Trump campaign’s ties to Russia during the 2016 campaign. The evidence for these ties — like the evidence that Mr. Trump sought a bribe from the Ukrainian president — is indisputable. So Republicans have instead attacked the investigation itself, claiming that it was the fruit of illegal actions by Trump-hating F.B.I. agents.\n",
        "Mr. Horowitz shot down that theory. The investigation was based on sufficient evidence of an ongoing national security threat, he found, and there was no evidence it was infected by anti-Trump political bias. In fact, Mr. Horowitz turned up evidence of agents who supported Mr. Trump. One wrote to another that he was \\\"so elated with the election,\\\" later explaining to the inspector general that he had opposed Hillary Clinton and “didn’t want a criminal to be in the White House.'\n",
        "Still, Mr. Horowitz harshly criticized the F.B.I. over what he called \\\"many basic and fundamental errors\\\" it made during the investigation, including mistakes or omissions in important paperwork that “made it appear that the information supporting probable cause was stronger than was actually the case.\\\"\n",
        "These are serious and in some cases alarming missteps and would be a concern in any case, let alone in one targeting people closely associated with a presidential campaign. But don’t be lulled into thinking Republicans care about surveillance overreach — just as they don’t care about Hillary Clinton’s emails or Joe Biden’s son. They’re simply casting about for anything that will protect their president from the scrutiny that he has invited upon himself since long before he was elected.\n",
        "For his part, Mr. Trump claimed that the report was 'everything that a lot of people thought it would be, except far worse.'\n",
        "This sort of brazen misrepresentation of facts is par for Mr. Trump’s course, and while it is sadly effective, it shouldn’t distract Americans from the emergency at hand: Whether Mr. Trump played footsie with Russians to win in 2016 or strong-armed a vulnerable new leader who is at war with Russia to win in 2020, he did exactly what the nation’s framers feared an unprincipled, power-hungry executive might do to hold onto his office. That’s why they put the impeachment power in the Constitution, and it’s why lawmakers who care about the Republic and its survival must use it.\n",
        "\"\"\"\n",
        "new_sentence = new_sentence.replace('.', '.\\n')\n",
        "\n",
        "print (\"FOLLOWING IS OUR TRAINING SEQUENCE:\")\n",
        "print (\"Length of 'test sentence' is %s\" %len(new_sentence))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOLLOWING IS OUR TRAINING SEQUENCE:\n",
            "Length of 'test sentence' is 7112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n4r1zFr7dIMj"
      },
      "source": [
        "### 입력 문자열과 타겟 문자 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0927b9a6-05af-48d3-e9cc-03b649d2a325",
        "id": "_EcjP8u4dIMl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "# make charater dictionary \n",
        "new_char_set = list(set(new_sentence))\n",
        "new_char_dic = {w: i for i, w in enumerate(new_char_set)}\n",
        "print (\"CHARACTERS :\", len(new_char_set))\n",
        "print (\"ㄴ\", new_char_set)\n",
        "print (\"DICTIONARY :\", len(new_char_dic))\n",
        "print ('ㄴ', new_char_dic)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CHARACTERS : 69\n",
            "ㄴ [',', '—', 'O', 'A', '4', '3', 'W', '-', 'C', 'b', 'y', '’', ' ', 'M', 'c', '0', 'h', 'u', 'Y', 'd', 'S', 'v', '“', 'r', 'i', 'w', 'J', '1', 'o', '.', \"'\", 'R', 'a', 's', 'P', 'z', 'n', 'g', 'H', 't', '\\n', 'N', 'q', '(', ')', 'T', 'L', '?', '\"', '2', '”', ':', 'F', 'V', 'D', 'j', 'I', 'f', ';', 'm', 'l', 'B', 'k', 'e', '6', 'x', 'p', 'U', 'Z']\n",
            "DICTIONARY : 69\n",
            "ㄴ {',': 0, '—': 1, 'O': 2, 'A': 3, '4': 4, '3': 5, 'W': 6, '-': 7, 'C': 8, 'b': 9, 'y': 10, '’': 11, ' ': 12, 'M': 13, 'c': 14, '0': 15, 'h': 16, 'u': 17, 'Y': 18, 'd': 19, 'S': 20, 'v': 21, '“': 22, 'r': 23, 'i': 24, 'w': 25, 'J': 26, '1': 27, 'o': 28, '.': 29, \"'\": 30, 'R': 31, 'a': 32, 's': 33, 'P': 34, 'z': 35, 'n': 36, 'g': 37, 'H': 38, 't': 39, '\\n': 40, 'N': 41, 'q': 42, '(': 43, ')': 44, 'T': 45, 'L': 46, '?': 47, '\"': 48, '2': 49, '”': 50, ':': 51, 'F': 52, 'V': 53, 'D': 54, 'j': 55, 'I': 56, 'f': 57, ';': 58, 'm': 59, 'l': 60, 'B': 61, 'k': 62, 'e': 63, '6': 64, 'x': 65, 'p': 66, 'U': 67, 'Z': 68}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "31dd8581-05cf-47cc-c32b-4d7e1a6d2821",
        "id": "aq8uZAWhdIMn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "new_data_dim    = len(new_char_set) # train data X:input\n",
        "new_num_classes = len(new_char_set) # trian data Y:target\n",
        "new_sequence_length = 10        # any arbitrary number\n",
        "print ('data_dim : %d' %new_data_dim)\n",
        "print ('num_classes : %d' %new_num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_dim : 69\n",
            "num_classes : 69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "90433f56-0d8d-4c02-aa5c-78311e5c2402",
        "id": "qnY1-U8qdIMp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "dataX = []  # input sequence list\n",
        "dataY = []  # target sequence list \n",
        "\n",
        "# we will make 170 sequences \n",
        "for i in range(0, len(new_sentence) - new_sequence_length):\n",
        "    # 10 characters = 1 training sequence\n",
        "    x_str = new_sentence[i : i+new_sequence_length]\n",
        "    y_str = new_sentence[i+1 : i+new_sequence_length+1]\n",
        "    # convert x, y str to index(int)\n",
        "    x_idx = [new_char_dic[c] for c in x_str] \n",
        "    y_idx = [new_char_dic[c] for c in y_str] \n",
        "    # append to dataset list\n",
        "    dataX.append(x_idx)\n",
        "    dataY.append(y_idx)\n",
        "\n",
        "    # monitoring\n",
        "    if i<5:\n",
        "        print (\"[%3d/%3d] [%s]=>[%s]\" % (i, len(new_sentence), x_str, y_str))\n",
        "        print (\"%s%s=>%s\" % (' '*10, x_idx, y_idx))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0/7112] [When it co]=>[hen it com]\n",
            "          [6, 16, 63, 36, 12, 24, 39, 12, 14, 28]=>[16, 63, 36, 12, 24, 39, 12, 14, 28, 59]\n",
            "[  1/7112] [hen it com]=>[en it come]\n",
            "          [16, 63, 36, 12, 24, 39, 12, 14, 28, 59]=>[63, 36, 12, 24, 39, 12, 14, 28, 59, 63]\n",
            "[  2/7112] [en it come]=>[n it comes]\n",
            "          [63, 36, 12, 24, 39, 12, 14, 28, 59, 63]=>[36, 12, 24, 39, 12, 14, 28, 59, 63, 33]\n",
            "[  3/7112] [n it comes]=>[ it comes ]\n",
            "          [36, 12, 24, 39, 12, 14, 28, 59, 63, 33]=>[12, 24, 39, 12, 14, 28, 59, 63, 33, 12]\n",
            "[  4/7112] [ it comes ]=>[it comes t]\n",
            "          [12, 24, 39, 12, 14, 28, 59, 63, 33, 12]=>[24, 39, 12, 14, 28, 59, 63, 33, 12, 39]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bhUNRYMLdIMr"
      },
      "source": [
        "### 입력문자 list를 3-dim로, 타겟문자 list를 2-dim로 변환  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "799d4ae6-d8aa-4407-9065-a360360d6026",
        "id": "_pGfZ7H3dIMs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# input tensor 생성 \n",
        "X = np.array(dataX)                                      # ndarray(170,10)<-[170,10]\n",
        "# convert list sequence to 3dim array(one-hot coding)\n",
        "sequences = [tf.keras.utils.to_categorical(\n",
        "                 x, num_classes = new_data_dim) for x in X]  # list[170,10,25]\n",
        "X = np.array(sequences)                                  # ndarray(170,10,25)\n",
        "print(\"shape of X :\", X.shape)\n",
        "\n",
        "# Target tensor 생성\n",
        "#y = np.array(dataY)[:,-1]                                # ndarray(170,)<-[170,10]\n",
        "y = np.array(dataY)                                       # ndarray(170,10)<-[170,10]\n",
        "print(\"shape of y :\", y.shape)\n",
        "\n",
        "# convert the vector to 2-dim \n",
        "y = tf.keras.utils.to_categorical(\n",
        "                  y, num_classes = new_data_dim)             # (170,25) -> (170,10,25)\n",
        "\n",
        "print (\"shape of y :\", y.shape)# (170,10,25)\n",
        "#print (y[0])    # t -> one-hot ,  (if you wan't')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of X : (7102, 10, 69)\n",
            "shape of y : (7102, 10)\n",
            "shape of y : (7102, 10, 69)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yoN6bqf-dIMu"
      },
      "source": [
        "## **Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3fMG0cf1dIMv"
      },
      "source": [
        "### Define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c09f65f6-3ee9-47cc-bb98-ccf94a27f107",
        "id": "QNpkFYlqdIMw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# Sequenctial model define: LSTM + Dense\n",
        "hidden_dim = 150\n",
        "model_2=tf.keras.models.Sequential(name='NewYorkTimes')\n",
        "model_2.add(tf.keras.layers.LSTM(hidden_dim,\n",
        "          input_shape=(new_sequence_length,new_num_classes),\n",
        "          return_sequences=True)) # (bs,10,hidden_dim)<-(bs,hidden_dim)\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model_2.add(tf.keras.layers.Dense(new_data_dim, activation='softmax'))\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"NewYorkTimes\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 10, 150)           132000    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10, 69)            10419     \n",
            "=================================================================\n",
            "Total params: 142,419\n",
            "Trainable params: 142,419\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nOeSQK0SdIMy"
      },
      "source": [
        "### Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MLxPAvdTdIMz",
        "colab": {}
      },
      "source": [
        "model_2.compile(loss ='categorical_crossentropy', # one-hot coding\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JP1-WaPhdIM1"
      },
      "source": [
        "### Fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jahHmb4SdIM1"
      },
      "source": [
        "Epoch 1000/1000   \n",
        "170/170 [==============================] - 0s 235us/sample - loss: 0.0012 - accuracy: 1.0000    \n",
        "CPU times: user 48.3 s, sys: 6.54 s, total: 54.8 s    \n",
        "Wall time: 47.8 s (@Notebook Setting/GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "85720dd3-4d2f-4d1b-c733-162f64fdb06b",
        "id": "_Y1M6vI6dIM2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "model_2.fit(X,            # X.shape : (170, 10, 25)\n",
        "            y,            # y.shape : (170, 10, 25)\n",
        "            epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7102 samples\n",
            "Epoch 1/100\n",
            "7102/7102 [==============================] - 4s 520us/sample - loss: 3.2367 - accuracy: 0.1755\n",
            "Epoch 2/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 2.6099 - accuracy: 0.3092\n",
            "Epoch 3/100\n",
            "7102/7102 [==============================] - 1s 159us/sample - loss: 2.2967 - accuracy: 0.3639\n",
            "Epoch 4/100\n",
            "7102/7102 [==============================] - 1s 160us/sample - loss: 2.1334 - accuracy: 0.3948\n",
            "Epoch 5/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 2.0139 - accuracy: 0.4236\n",
            "Epoch 6/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 1.9125 - accuracy: 0.4487\n",
            "Epoch 7/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 1.8202 - accuracy: 0.4696\n",
            "Epoch 8/100\n",
            "7102/7102 [==============================] - 1s 159us/sample - loss: 1.7298 - accuracy: 0.4953\n",
            "Epoch 9/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 1.6471 - accuracy: 0.5166\n",
            "Epoch 10/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 1.5649 - accuracy: 0.5388\n",
            "Epoch 11/100\n",
            "7102/7102 [==============================] - 1s 160us/sample - loss: 1.4920 - accuracy: 0.5600\n",
            "Epoch 12/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 1.4208 - accuracy: 0.5796\n",
            "Epoch 13/100\n",
            "7102/7102 [==============================] - 1s 157us/sample - loss: 1.3573 - accuracy: 0.5963\n",
            "Epoch 14/100\n",
            "7102/7102 [==============================] - 1s 160us/sample - loss: 1.2948 - accuracy: 0.6151\n",
            "Epoch 15/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 1.2406 - accuracy: 0.6321\n",
            "Epoch 16/100\n",
            "7102/7102 [==============================] - 1s 159us/sample - loss: 1.1895 - accuracy: 0.6470\n",
            "Epoch 17/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 1.1439 - accuracy: 0.6602\n",
            "Epoch 18/100\n",
            "7102/7102 [==============================] - 1s 165us/sample - loss: 1.1000 - accuracy: 0.6755\n",
            "Epoch 19/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 1.0613 - accuracy: 0.6868\n",
            "Epoch 20/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 1.0257 - accuracy: 0.6972\n",
            "Epoch 21/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.9935 - accuracy: 0.7082\n",
            "Epoch 22/100\n",
            "7102/7102 [==============================] - 1s 167us/sample - loss: 0.9654 - accuracy: 0.7151\n",
            "Epoch 23/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 0.9389 - accuracy: 0.7234\n",
            "Epoch 24/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.9162 - accuracy: 0.7279\n",
            "Epoch 25/100\n",
            "7102/7102 [==============================] - 1s 164us/sample - loss: 0.8957 - accuracy: 0.7338\n",
            "Epoch 26/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 0.8768 - accuracy: 0.7398\n",
            "Epoch 27/100\n",
            "7102/7102 [==============================] - 1s 168us/sample - loss: 0.8584 - accuracy: 0.7438\n",
            "Epoch 28/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.8438 - accuracy: 0.7470\n",
            "Epoch 29/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 0.8303 - accuracy: 0.7503\n",
            "Epoch 30/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 0.8170 - accuracy: 0.7529\n",
            "Epoch 31/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.8061 - accuracy: 0.7550\n",
            "Epoch 32/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.7948 - accuracy: 0.7582\n",
            "Epoch 33/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.7860 - accuracy: 0.7600\n",
            "Epoch 34/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 0.7770 - accuracy: 0.7615\n",
            "Epoch 35/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 0.7695 - accuracy: 0.7630\n",
            "Epoch 36/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.7622 - accuracy: 0.7637\n",
            "Epoch 37/100\n",
            "7102/7102 [==============================] - 1s 160us/sample - loss: 0.7550 - accuracy: 0.7662\n",
            "Epoch 38/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 0.7493 - accuracy: 0.7664\n",
            "Epoch 39/100\n",
            "7102/7102 [==============================] - 1s 164us/sample - loss: 0.7424 - accuracy: 0.7682\n",
            "Epoch 40/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 0.7375 - accuracy: 0.7680\n",
            "Epoch 41/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.7324 - accuracy: 0.7699\n",
            "Epoch 42/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.7280 - accuracy: 0.7703\n",
            "Epoch 43/100\n",
            "7102/7102 [==============================] - 1s 169us/sample - loss: 0.7235 - accuracy: 0.7705\n",
            "Epoch 44/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 0.7191 - accuracy: 0.7713\n",
            "Epoch 45/100\n",
            "7102/7102 [==============================] - 1s 164us/sample - loss: 0.7143 - accuracy: 0.7729\n",
            "Epoch 46/100\n",
            "7102/7102 [==============================] - 1s 167us/sample - loss: 0.7123 - accuracy: 0.7730\n",
            "Epoch 47/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 0.7090 - accuracy: 0.7733\n",
            "Epoch 48/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 0.7047 - accuracy: 0.7735\n",
            "Epoch 49/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 0.7019 - accuracy: 0.7747\n",
            "Epoch 50/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 0.6994 - accuracy: 0.7744\n",
            "Epoch 51/100\n",
            "7102/7102 [==============================] - 1s 160us/sample - loss: 0.6962 - accuracy: 0.7751\n",
            "Epoch 52/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.6932 - accuracy: 0.7757\n",
            "Epoch 53/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.6913 - accuracy: 0.7758\n",
            "Epoch 54/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 0.6884 - accuracy: 0.7754\n",
            "Epoch 55/100\n",
            "7102/7102 [==============================] - 1s 166us/sample - loss: 0.6858 - accuracy: 0.7763\n",
            "Epoch 56/100\n",
            "7102/7102 [==============================] - 1s 160us/sample - loss: 0.6839 - accuracy: 0.7772\n",
            "Epoch 57/100\n",
            "7102/7102 [==============================] - 1s 164us/sample - loss: 0.6818 - accuracy: 0.7760\n",
            "Epoch 58/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.6797 - accuracy: 0.7770\n",
            "Epoch 59/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 0.6781 - accuracy: 0.7772\n",
            "Epoch 60/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 0.6761 - accuracy: 0.7773\n",
            "Epoch 61/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 0.6746 - accuracy: 0.7781\n",
            "Epoch 62/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.6717 - accuracy: 0.7781\n",
            "Epoch 63/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 0.6712 - accuracy: 0.7782\n",
            "Epoch 64/100\n",
            "7102/7102 [==============================] - 1s 165us/sample - loss: 0.6701 - accuracy: 0.7783\n",
            "Epoch 65/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 0.6689 - accuracy: 0.7778\n",
            "Epoch 66/100\n",
            "7102/7102 [==============================] - 1s 164us/sample - loss: 0.6671 - accuracy: 0.7791\n",
            "Epoch 67/100\n",
            "7102/7102 [==============================] - 1s 161us/sample - loss: 0.6646 - accuracy: 0.7788\n",
            "Epoch 68/100\n",
            "7102/7102 [==============================] - 1s 159us/sample - loss: 0.6638 - accuracy: 0.7781\n",
            "Epoch 69/100\n",
            "7102/7102 [==============================] - 1s 165us/sample - loss: 0.6629 - accuracy: 0.7788\n",
            "Epoch 70/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.6621 - accuracy: 0.7792\n",
            "Epoch 71/100\n",
            "7102/7102 [==============================] - 1s 168us/sample - loss: 0.6607 - accuracy: 0.7792\n",
            "Epoch 72/100\n",
            "7102/7102 [==============================] - 1s 164us/sample - loss: 0.6600 - accuracy: 0.7781\n",
            "Epoch 73/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 0.6583 - accuracy: 0.7791\n",
            "Epoch 74/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 0.6569 - accuracy: 0.7795\n",
            "Epoch 75/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 0.6563 - accuracy: 0.7787\n",
            "Epoch 76/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 0.6559 - accuracy: 0.7795\n",
            "Epoch 77/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.6538 - accuracy: 0.7812\n",
            "Epoch 78/100\n",
            "7102/7102 [==============================] - 1s 164us/sample - loss: 0.6534 - accuracy: 0.7788\n",
            "Epoch 79/100\n",
            "7102/7102 [==============================] - 1s 174us/sample - loss: 0.6522 - accuracy: 0.7798\n",
            "Epoch 80/100\n",
            "7102/7102 [==============================] - 1s 165us/sample - loss: 0.6521 - accuracy: 0.7785\n",
            "Epoch 81/100\n",
            "7102/7102 [==============================] - 1s 168us/sample - loss: 0.6508 - accuracy: 0.7788\n",
            "Epoch 82/100\n",
            "7102/7102 [==============================] - 1s 173us/sample - loss: 0.6513 - accuracy: 0.7790\n",
            "Epoch 83/100\n",
            "7102/7102 [==============================] - 1s 165us/sample - loss: 0.6498 - accuracy: 0.7792\n",
            "Epoch 84/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.6484 - accuracy: 0.7794\n",
            "Epoch 85/100\n",
            "7102/7102 [==============================] - 1s 160us/sample - loss: 0.6480 - accuracy: 0.7804\n",
            "Epoch 86/100\n",
            "7102/7102 [==============================] - 1s 166us/sample - loss: 0.6463 - accuracy: 0.7799\n",
            "Epoch 87/100\n",
            "7102/7102 [==============================] - 1s 166us/sample - loss: 0.6459 - accuracy: 0.7805\n",
            "Epoch 88/100\n",
            "7102/7102 [==============================] - 1s 160us/sample - loss: 0.6464 - accuracy: 0.7799\n",
            "Epoch 89/100\n",
            "7102/7102 [==============================] - 1s 162us/sample - loss: 0.6444 - accuracy: 0.7799\n",
            "Epoch 90/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.6442 - accuracy: 0.7801\n",
            "Epoch 91/100\n",
            "7102/7102 [==============================] - 1s 169us/sample - loss: 0.6429 - accuracy: 0.7800\n",
            "Epoch 92/100\n",
            "7102/7102 [==============================] - 1s 167us/sample - loss: 0.6430 - accuracy: 0.7799\n",
            "Epoch 93/100\n",
            "7102/7102 [==============================] - 1s 163us/sample - loss: 0.6425 - accuracy: 0.7789\n",
            "Epoch 94/100\n",
            "7102/7102 [==============================] - 1s 168us/sample - loss: 0.6424 - accuracy: 0.7795\n",
            "Epoch 95/100\n",
            "7102/7102 [==============================] - 1s 168us/sample - loss: 0.6404 - accuracy: 0.7816\n",
            "Epoch 96/100\n",
            "7102/7102 [==============================] - 1s 164us/sample - loss: 0.6415 - accuracy: 0.7798\n",
            "Epoch 97/100\n",
            "7102/7102 [==============================] - 1s 166us/sample - loss: 0.6400 - accuracy: 0.7804\n",
            "Epoch 98/100\n",
            "7102/7102 [==============================] - 1s 159us/sample - loss: 0.6389 - accuracy: 0.7806\n",
            "Epoch 99/100\n",
            "7102/7102 [==============================] - 1s 164us/sample - loss: 0.6389 - accuracy: 0.7798\n",
            "Epoch 100/100\n",
            "7102/7102 [==============================] - 1s 165us/sample - loss: 0.6383 - accuracy: 0.7809\n",
            "CPU times: user 2min 34s, sys: 15.7 s, total: 2min 50s\n",
            "Wall time: 1min 58s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f51a7d4e518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GHetD-16dIM4"
      },
      "source": [
        "## **Generate Text:** analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2x0YIkIZdIM4"
      },
      "source": [
        "### Related Module Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uqL5wNU_dIM5"
      },
      "source": [
        "### Define generate_seq function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_RataChCdIM6",
        "outputId": "6e6a8e6b-eea6-4fb6-ac6e-41edeb913720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "print('Trigger characters: \"When it co \"\\nResult: \\n\"{}\"'.format( \n",
        "      generate_seq(model_2, new_char_dic, new_sequence_length, 'When it co', 200)))\n",
        "\n",
        "print('\\nTrigger characters: \"their best\"\\nResult: \\n\"{}\"'.format(\n",
        "      generate_seq(model_2, new_char_dic, new_sequence_length, 'their best', 200)))\n",
        "\n",
        "print('\\nTrigger characters: \"in an inte\"\\nResult: \"{}\"'.format(\n",
        "      generate_seq(model_2, new_char_dic, new_sequence_length, 'in an inte', 200)))\n",
        "\n",
        "print('\\nTrigger characters: \"hello \"\\nResult: \"{}\"'.format(\n",
        "      generate_seq(model_2, new_char_dic, new_sequence_length, 'hello ', 200)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trigger characters: \"When it co \"\n",
            "Result: \n",
            "\"When it comes to Donald Trump and Russia, everything is connected.\n",
            "\n",
            "That’s the most damning facts brought forward about a president were a Democrat, of course.\n",
            ")\n",
            "The emptiness of the Republicans continued to do\"\n",
            "\n",
            "Trigger characters: \"their best\"\n",
            "Result: \n",
            "\"their best to obfuscate and misdirect, as they have done throughout the impeachment and the release of the report was 'everything is connected.\n",
            "\n",
            "That’s the most damning facts brought forward about a president w\"\n",
            "\n",
            "Trigger characters: \"in an inte\"\n",
            "Result: \"in an interruption by Representative Jerry Nadler, the chairman of the Judiciary Committee’s Democratic counsel, testified that President Trump’s impeachment and the release of the report was 'everything is con\"\n",
            "\n",
            "Trigger characters: \"hello \"\n",
            "Result: \"hello actory bas baser that the founders were most concerned about when they hear it, is a skill that has become increasingly foreign to Republicans continued to do their best to obfuscate and misdirect, as\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONQTnjxCehza",
        "colab_type": "code",
        "outputId": "70cc9c04-914b-4a17-f51a-b8a737d2bb1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "print('\\nTrigger characters: \"kwonyo\"\\nResult: \"{}\"'.format(\n",
        "      generate_seq(model_2, new_char_dic, new_sequence_length, 'kwonyo', 200)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Trigger characters: \"kwonyo\"\n",
            "Result: \"kwonyon and “didn’t want a criminal to be in the White House.\n",
            "'\n",
            "Still, Mr.\n",
            " Horowitz harshly criticized the F.\n",
            "B.\n",
            "I.\n",
            "’s investigation was based on sufficient evidence of agents who supported Mr.\n",
            " Trump is p\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2CHpa5CnTmN",
        "colab_type": "code",
        "outputId": "ccb4fbf5-a799-47f8-c7f1-af2a18cb8a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print('\\nTrigger characters: \"kwonyo\"\\nResult: \"{}\"'.format(\n",
        "      generate_seq(model_2, new_char_dic, new_sequence_length, 'kwonyo', 50)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Trigger characters: \"kwonyo\"\n",
            "Result: \"kwonyon and “didn’t want a criminal to be in the White H\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUQjVIqOnYE8",
        "colab_type": "code",
        "outputId": "5bd7828f-27e4-4259-fd17-dacb35f0db46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print('\\nTrigger characters: \"kwonyo\"\\nResult: \"{}\"'.format(\n",
        "      generate_seq(model_2, new_char_dic, new_sequence_length, 'kwonyo', 10)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Trigger characters: \"kwonyo\"\n",
            "Result: \"kwonyon and “did\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWwCPMyznfiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}