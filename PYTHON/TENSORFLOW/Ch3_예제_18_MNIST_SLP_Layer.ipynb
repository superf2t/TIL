{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch3_예제_18_MNIST_SLP_Layer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KwonYN/TIL/blob/master/PYTHON/TENSORFLOW/Ch3_%EC%98%88%EC%A0%9C_18_MNIST_SLP_Layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERQax80Nl2fY",
        "colab_type": "text"
      },
      "source": [
        "# Chapter3-5. Deep Learning 기초 : Multi Layer Perceptron (MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvu8nWycl9Qp",
        "colab_type": "text"
      },
      "source": [
        ">## [예제3-17] MNIST Classification : SLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba-LxKfLmGVu",
        "colab_type": "text"
      },
      "source": [
        ">### Load modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXxAYyqxlNxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "66deceaa-ba12-4673-ac71-ba259afddbaf"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "print(\"Module Loaded.\")\n",
        "print(\"NumPy Version :{}\".format(np.__version__))\n",
        "print(\"TensorFlow Version :{}\".format(tf.__version__))\n",
        "print(\"Matplotlib Version :{}\".format(plt.matplotlib.__version__))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Module Loaded.\n",
            "NumPy Version :1.17.4\n",
            "TensorFlow Version :1.15.0\n",
            "Matplotlib Version :3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tdKm3VimauR",
        "colab_type": "text"
      },
      "source": [
        "> ### Load MNIST Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMhaNhF0mIXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "26049505-5d91-43fc-a27a-de4f6689e18a"
      },
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
        "\n",
        "train_data = train_data.astype(np.float32)\n",
        "train_data = train_data / 255.0\n",
        "\n",
        "test_data = test_data.astype(np.float32)\n",
        "test_data = test_data / 255.0\n",
        "\n",
        "train_labels = train_labels.reshape((-1, 1))\n",
        "test_labels = test_labels.reshape((-1, 1))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgFlDyu-mgHN",
        "colab_type": "text"
      },
      "source": [
        "> ### Placeholder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vse7W7x7mh8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_ph = tf.placeholder(tf.float32, shape=(None, 28, 28), name = \"input\")\n",
        "labels_ph = tf.placeholder(tf.int32, shape=(None,1), name=\"labels\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7v1V11kmrRz",
        "colab_type": "text"
      },
      "source": [
        ">### Hypothesis, Cost, Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gk1hqtjmhyb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "85cc160a-ebe8-4819-ba52-e845ba4d5106"
      },
      "source": [
        "categories = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "x_flatten = tf.layers.flatten(x_ph) # (?, 28, 28) -> (?, 784)\n",
        "logits = tf.layers.dense(x_flatten, categories, kernel_initializer=tf.random_normal_initializer, bias_initializer=tf.random_normal_initializer) # tf.matmul(x_ph, w) + b\n",
        "hypothesis = tf.nn.softmax(logits)\n",
        "\n",
        "labels_oh = tf.one_hot(labels_ph, categories)\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels_oh, logits))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "train = optimizer.minimize(cost)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-9fa2ef33b012>:4: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-4-9fa2ef33b012>:5: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXTYroJlnZzc",
        "colab_type": "text"
      },
      "source": [
        ">### Mini-Batch 관련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT7MkX6NDE9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_epoch = 1000\n",
        "batch_size = 100\n",
        "train_data_size = train_data.shape\n",
        "batch_count = train_data_size[0] //batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odw3CRkBDNmQ",
        "colab_type": "text"
      },
      "source": [
        ">### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1mBO7zSnaVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Accuracy(y:np.ndarray, t:np.ndarray)->np.float32:\n",
        "    return np.mean(np.equal(np.argmax(y, axis=1).reshape((-1, 1)),t).astype(np.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYroAqw9N8ZP",
        "colab_type": "text"
      },
      "source": [
        ">### 결과 출력을 위한 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-bIPKAdN8Mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Make_Result_Plot(suptitle:str, data:np.ndarray, label:np.ndarray, y_max:np.ndarray):\n",
        "    fig_result, ax_result = plt.subplots(2,5,figsize=(18, 7))\n",
        "    fig_result.suptitle(suptitle)\n",
        "    for idx in range(10):\n",
        "        ax_result[idx//5][idx%5].imshow(data[idx].reshape((28,28)),cmap=\"binary\")\n",
        "        ax_result[idx//5][idx%5].set_title(\"test_data[{}] (label : {} / y : {})\".format(idx, label[idx], y_max[idx]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Csh_RwwRTQ1Q",
        "colab_type": "text"
      },
      "source": [
        "> ### Training 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmmynBowTQQS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "37d58c9f-203f-475f-f657-d114f077af12"
      },
      "source": [
        "arr_epoch = []\n",
        "arr_accu = []\n",
        "\n",
        "# 학습 (Training)\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "train_data_idx = np.arange(train_data_size[0])\n",
        "\n",
        "y_out = sess.run(hypothesis, feed_dict={x_ph: test_data})\n",
        "y_max = np.argmax(y_out, axis=1).reshape((-1, 1))\n",
        "Make_Result_Plot(\"Before Training\", test_data, test_labels, y_max)\n",
        "\n",
        "accu = Accuracy(y_out,test_labels)\n",
        "arr_epoch.append(0)\n",
        "arr_accu.append(accu)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABBgAAAHOCAYAAAAyvrr8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nR3g55QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1296x504 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dhfsRZQnm-C",
        "colab_type": "text"
      },
      "source": [
        "> ### 학습 (Training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-3I0oV_nnYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "155fb0ec-f793-4d22-90ed-0f8396a4c3a2"
      },
      "source": [
        "%%time\n",
        "for epoch_idx in range(1, N_epoch+1):\n",
        "    np.random.shuffle(train_data_idx)\n",
        "    for batch_idx in range(batch_count):\n",
        "        batch_data = np.array([train_data[train_data_idx[idx]] for idx in range(batch_size)])\n",
        "        batch_labels = np.array([train_labels[train_data_idx[idx]] for idx in range(batch_size)])\n",
        "        sess.run(train, feed_dict={x_ph: batch_data, labels_ph: batch_labels})\n",
        "    if epoch_idx%1 == 0:\n",
        "        y_out = sess.run(hypothesis, feed_dict={x_ph: test_data})\n",
        "        accu = Accuracy(y_out,test_labels)\n",
        "        print(\"[{:>5}] accuracy = {:>10.4}\".format(epoch_idx,accu))\n",
        "        arr_epoch.append(epoch_idx)\n",
        "        arr_accu.append(accu)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    1] accuracy =     0.1474\n",
            "[    2] accuracy =     0.1746\n",
            "[    3] accuracy =     0.2054\n",
            "[    4] accuracy =     0.2223\n",
            "[    5] accuracy =     0.2404\n",
            "[    6] accuracy =     0.2601\n",
            "[    7] accuracy =     0.2887\n",
            "[    8] accuracy =     0.3083\n",
            "[    9] accuracy =     0.3345\n",
            "[   10] accuracy =     0.3483\n",
            "[   11] accuracy =     0.3653\n",
            "[   12] accuracy =     0.3851\n",
            "[   13] accuracy =     0.4019\n",
            "[   14] accuracy =     0.4104\n",
            "[   15] accuracy =     0.4277\n",
            "[   16] accuracy =     0.4398\n",
            "[   17] accuracy =     0.4552\n",
            "[   18] accuracy =      0.471\n",
            "[   19] accuracy =     0.4838\n",
            "[   20] accuracy =     0.4929\n",
            "[   21] accuracy =     0.5042\n",
            "[   22] accuracy =     0.5106\n",
            "[   23] accuracy =     0.5162\n",
            "[   24] accuracy =     0.5225\n",
            "[   25] accuracy =     0.5393\n",
            "[   26] accuracy =      0.546\n",
            "[   27] accuracy =     0.5595\n",
            "[   28] accuracy =     0.5667\n",
            "[   29] accuracy =     0.5757\n",
            "[   30] accuracy =      0.576\n",
            "[   31] accuracy =     0.5816\n",
            "[   32] accuracy =     0.5909\n",
            "[   33] accuracy =     0.5971\n",
            "[   34] accuracy =     0.6009\n",
            "[   35] accuracy =     0.6089\n",
            "[   36] accuracy =     0.6065\n",
            "[   37] accuracy =     0.6183\n",
            "[   38] accuracy =     0.6197\n",
            "[   39] accuracy =      0.625\n",
            "[   40] accuracy =     0.6215\n",
            "[   41] accuracy =     0.6277\n",
            "[   42] accuracy =     0.6258\n",
            "[   43] accuracy =     0.6355\n",
            "[   44] accuracy =     0.6411\n",
            "[   45] accuracy =      0.654\n",
            "[   46] accuracy =      0.657\n",
            "[   47] accuracy =     0.6526\n",
            "[   48] accuracy =     0.6627\n",
            "[   49] accuracy =      0.665\n",
            "[   50] accuracy =     0.6726\n",
            "[   51] accuracy =     0.6749\n",
            "[   52] accuracy =     0.6761\n",
            "[   53] accuracy =     0.6807\n",
            "[   54] accuracy =     0.6785\n",
            "[   55] accuracy =     0.6846\n",
            "[   56] accuracy =     0.6888\n",
            "[   57] accuracy =     0.6881\n",
            "[   58] accuracy =     0.6896\n",
            "[   59] accuracy =     0.6916\n",
            "[   60] accuracy =     0.6924\n",
            "[   61] accuracy =     0.6985\n",
            "[   62] accuracy =     0.6935\n",
            "[   63] accuracy =     0.6973\n",
            "[   64] accuracy =     0.7014\n",
            "[   65] accuracy =     0.7035\n",
            "[   66] accuracy =      0.706\n",
            "[   67] accuracy =     0.7108\n",
            "[   68] accuracy =     0.7139\n",
            "[   69] accuracy =     0.7123\n",
            "[   70] accuracy =      0.718\n",
            "[   71] accuracy =     0.7196\n",
            "[   72] accuracy =     0.7169\n",
            "[   73] accuracy =      0.725\n",
            "[   74] accuracy =     0.7255\n",
            "[   75] accuracy =     0.7298\n",
            "[   76] accuracy =     0.7293\n",
            "[   77] accuracy =     0.7298\n",
            "[   78] accuracy =     0.7319\n",
            "[   79] accuracy =     0.7304\n",
            "[   80] accuracy =     0.7292\n",
            "[   81] accuracy =     0.7338\n",
            "[   82] accuracy =      0.727\n",
            "[   83] accuracy =     0.7298\n",
            "[   84] accuracy =     0.7326\n",
            "[   85] accuracy =     0.7364\n",
            "[   86] accuracy =     0.7353\n",
            "[   87] accuracy =     0.7407\n",
            "[   88] accuracy =     0.7465\n",
            "[   89] accuracy =     0.7449\n",
            "[   90] accuracy =     0.7466\n",
            "[   91] accuracy =     0.7508\n",
            "[   92] accuracy =     0.7471\n",
            "[   93] accuracy =     0.7532\n",
            "[   94] accuracy =     0.7565\n",
            "[   95] accuracy =     0.7498\n",
            "[   96] accuracy =      0.755\n",
            "[   97] accuracy =     0.7613\n",
            "[   98] accuracy =     0.7601\n",
            "[   99] accuracy =     0.7605\n",
            "[  100] accuracy =     0.7633\n",
            "[  101] accuracy =     0.7641\n",
            "[  102] accuracy =     0.7635\n",
            "[  103] accuracy =     0.7633\n",
            "[  104] accuracy =     0.7629\n",
            "[  105] accuracy =     0.7634\n",
            "[  106] accuracy =     0.7634\n",
            "[  107] accuracy =     0.7612\n",
            "[  108] accuracy =      0.764\n",
            "[  109] accuracy =     0.7703\n",
            "[  110] accuracy =     0.7698\n",
            "[  111] accuracy =     0.7694\n",
            "[  112] accuracy =     0.7718\n",
            "[  113] accuracy =     0.7679\n",
            "[  114] accuracy =     0.7684\n",
            "[  115] accuracy =     0.7694\n",
            "[  116] accuracy =     0.7699\n",
            "[  117] accuracy =     0.7664\n",
            "[  118] accuracy =     0.7639\n",
            "[  119] accuracy =     0.7705\n",
            "[  120] accuracy =     0.7701\n",
            "[  121] accuracy =     0.7705\n",
            "[  122] accuracy =     0.7764\n",
            "[  123] accuracy =     0.7771\n",
            "[  124] accuracy =     0.7805\n",
            "[  125] accuracy =     0.7792\n",
            "[  126] accuracy =     0.7795\n",
            "[  127] accuracy =     0.7804\n",
            "[  128] accuracy =     0.7775\n",
            "[  129] accuracy =     0.7814\n",
            "[  130] accuracy =     0.7844\n",
            "[  131] accuracy =     0.7867\n",
            "[  132] accuracy =     0.7879\n",
            "[  133] accuracy =     0.7847\n",
            "[  134] accuracy =      0.786\n",
            "[  135] accuracy =     0.7836\n",
            "[  136] accuracy =     0.7838\n",
            "[  137] accuracy =      0.789\n",
            "[  138] accuracy =      0.789\n",
            "[  139] accuracy =     0.7844\n",
            "[  140] accuracy =     0.7842\n",
            "[  141] accuracy =     0.7895\n",
            "[  142] accuracy =     0.7895\n",
            "[  143] accuracy =     0.7946\n",
            "[  144] accuracy =     0.7925\n",
            "[  145] accuracy =     0.7934\n",
            "[  146] accuracy =     0.7931\n",
            "[  147] accuracy =     0.7933\n",
            "[  148] accuracy =     0.7965\n",
            "[  149] accuracy =     0.7954\n",
            "[  150] accuracy =     0.7948\n",
            "[  151] accuracy =     0.7961\n",
            "[  152] accuracy =     0.7924\n",
            "[  153] accuracy =     0.7952\n",
            "[  154] accuracy =      0.797\n",
            "[  155] accuracy =     0.7929\n",
            "[  156] accuracy =     0.7925\n",
            "[  157] accuracy =     0.7924\n",
            "[  158] accuracy =     0.7966\n",
            "[  159] accuracy =     0.7997\n",
            "[  160] accuracy =      0.799\n",
            "[  161] accuracy =     0.7999\n",
            "[  162] accuracy =     0.8026\n",
            "[  163] accuracy =     0.8011\n",
            "[  164] accuracy =     0.8017\n",
            "[  165] accuracy =     0.8004\n",
            "[  166] accuracy =     0.7967\n",
            "[  167] accuracy =     0.7974\n",
            "[  168] accuracy =     0.7993\n",
            "[  169] accuracy =     0.7922\n",
            "[  170] accuracy =     0.7997\n",
            "[  171] accuracy =     0.7994\n",
            "[  172] accuracy =     0.8013\n",
            "[  173] accuracy =     0.8037\n",
            "[  174] accuracy =     0.8004\n",
            "[  175] accuracy =     0.8036\n",
            "[  176] accuracy =     0.8025\n",
            "[  177] accuracy =     0.8054\n",
            "[  178] accuracy =      0.806\n",
            "[  179] accuracy =     0.8013\n",
            "[  180] accuracy =      0.808\n",
            "[  181] accuracy =       0.81\n",
            "[  182] accuracy =     0.8102\n",
            "[  183] accuracy =     0.8109\n",
            "[  184] accuracy =     0.8107\n",
            "[  185] accuracy =     0.8139\n",
            "[  186] accuracy =     0.8097\n",
            "[  187] accuracy =     0.8094\n",
            "[  188] accuracy =     0.8111\n",
            "[  189] accuracy =     0.8087\n",
            "[  190] accuracy =     0.8123\n",
            "[  191] accuracy =     0.8078\n",
            "[  192] accuracy =     0.8071\n",
            "[  193] accuracy =     0.8092\n",
            "[  194] accuracy =     0.8128\n",
            "[  195] accuracy =     0.8145\n",
            "[  196] accuracy =     0.8114\n",
            "[  197] accuracy =     0.8124\n",
            "[  198] accuracy =     0.8125\n",
            "[  199] accuracy =     0.8143\n",
            "[  200] accuracy =     0.8131\n",
            "[  201] accuracy =     0.8146\n",
            "[  202] accuracy =     0.8144\n",
            "[  203] accuracy =     0.8131\n",
            "[  204] accuracy =     0.8144\n",
            "[  205] accuracy =     0.8157\n",
            "[  206] accuracy =     0.8162\n",
            "[  207] accuracy =     0.8143\n",
            "[  208] accuracy =      0.817\n",
            "[  209] accuracy =     0.8173\n",
            "[  210] accuracy =     0.8136\n",
            "[  211] accuracy =     0.8172\n",
            "[  212] accuracy =     0.8162\n",
            "[  213] accuracy =     0.8185\n",
            "[  214] accuracy =     0.8234\n",
            "[  215] accuracy =     0.8217\n",
            "[  216] accuracy =     0.8247\n",
            "[  217] accuracy =      0.825\n",
            "[  218] accuracy =      0.822\n",
            "[  219] accuracy =     0.8221\n",
            "[  220] accuracy =     0.8221\n",
            "[  221] accuracy =     0.8262\n",
            "[  222] accuracy =     0.8245\n",
            "[  223] accuracy =     0.8244\n",
            "[  224] accuracy =     0.8231\n",
            "[  225] accuracy =     0.8175\n",
            "[  226] accuracy =     0.8235\n",
            "[  227] accuracy =     0.8223\n",
            "[  228] accuracy =     0.8195\n",
            "[  229] accuracy =     0.8221\n",
            "[  230] accuracy =     0.8234\n",
            "[  231] accuracy =     0.8246\n",
            "[  232] accuracy =     0.8268\n",
            "[  233] accuracy =     0.8268\n",
            "[  234] accuracy =     0.8231\n",
            "[  235] accuracy =     0.8269\n",
            "[  236] accuracy =     0.8266\n",
            "[  237] accuracy =     0.8256\n",
            "[  238] accuracy =     0.8287\n",
            "[  239] accuracy =     0.8258\n",
            "[  240] accuracy =     0.8258\n",
            "[  241] accuracy =     0.8263\n",
            "[  242] accuracy =     0.8271\n",
            "[  243] accuracy =      0.828\n",
            "[  244] accuracy =     0.8262\n",
            "[  245] accuracy =     0.8276\n",
            "[  246] accuracy =     0.8281\n",
            "[  247] accuracy =     0.8291\n",
            "[  248] accuracy =     0.8301\n",
            "[  249] accuracy =      0.829\n",
            "[  250] accuracy =     0.8276\n",
            "[  251] accuracy =     0.8274\n",
            "[  252] accuracy =     0.8313\n",
            "[  253] accuracy =     0.8317\n",
            "[  254] accuracy =     0.8313\n",
            "[  255] accuracy =     0.8296\n",
            "[  256] accuracy =     0.8305\n",
            "[  257] accuracy =     0.8308\n",
            "[  258] accuracy =     0.8326\n",
            "[  259] accuracy =     0.8299\n",
            "[  260] accuracy =     0.8273\n",
            "[  261] accuracy =     0.8208\n",
            "[  262] accuracy =     0.8254\n",
            "[  263] accuracy =     0.8295\n",
            "[  264] accuracy =     0.8312\n",
            "[  265] accuracy =     0.8267\n",
            "[  266] accuracy =     0.8276\n",
            "[  267] accuracy =     0.8298\n",
            "[  268] accuracy =     0.8289\n",
            "[  269] accuracy =     0.8282\n",
            "[  270] accuracy =     0.8265\n",
            "[  271] accuracy =     0.8288\n",
            "[  272] accuracy =     0.8312\n",
            "[  273] accuracy =     0.8305\n",
            "[  274] accuracy =      0.834\n",
            "[  275] accuracy =     0.8348\n",
            "[  276] accuracy =     0.8349\n",
            "[  277] accuracy =     0.8364\n",
            "[  278] accuracy =     0.8378\n",
            "[  279] accuracy =     0.8369\n",
            "[  280] accuracy =     0.8382\n",
            "[  281] accuracy =     0.8343\n",
            "[  282] accuracy =     0.8373\n",
            "[  283] accuracy =      0.837\n",
            "[  284] accuracy =     0.8356\n",
            "[  285] accuracy =     0.8325\n",
            "[  286] accuracy =     0.8359\n",
            "[  287] accuracy =     0.8355\n",
            "[  288] accuracy =     0.8379\n",
            "[  289] accuracy =     0.8353\n",
            "[  290] accuracy =     0.8299\n",
            "[  291] accuracy =     0.8309\n",
            "[  292] accuracy =     0.8318\n",
            "[  293] accuracy =     0.8385\n",
            "[  294] accuracy =     0.8369\n",
            "[  295] accuracy =     0.8356\n",
            "[  296] accuracy =     0.8364\n",
            "[  297] accuracy =     0.8364\n",
            "[  298] accuracy =     0.8362\n",
            "[  299] accuracy =     0.8324\n",
            "[  300] accuracy =     0.8323\n",
            "[  301] accuracy =     0.8329\n",
            "[  302] accuracy =     0.8372\n",
            "[  303] accuracy =     0.8353\n",
            "[  304] accuracy =     0.8353\n",
            "[  305] accuracy =     0.8342\n",
            "[  306] accuracy =     0.8337\n",
            "[  307] accuracy =     0.8341\n",
            "[  308] accuracy =     0.8357\n",
            "[  309] accuracy =     0.8388\n",
            "[  310] accuracy =     0.8399\n",
            "[  311] accuracy =     0.8393\n",
            "[  312] accuracy =     0.8381\n",
            "[  313] accuracy =     0.8372\n",
            "[  314] accuracy =      0.839\n",
            "[  315] accuracy =     0.8392\n",
            "[  316] accuracy =     0.8389\n",
            "[  317] accuracy =      0.839\n",
            "[  318] accuracy =       0.84\n",
            "[  319] accuracy =     0.8395\n",
            "[  320] accuracy =     0.8402\n",
            "[  321] accuracy =     0.8402\n",
            "[  322] accuracy =     0.8403\n",
            "[  323] accuracy =     0.8414\n",
            "[  324] accuracy =     0.8389\n",
            "[  325] accuracy =     0.8373\n",
            "[  326] accuracy =     0.8393\n",
            "[  327] accuracy =     0.8408\n",
            "[  328] accuracy =     0.8406\n",
            "[  329] accuracy =     0.8426\n",
            "[  330] accuracy =     0.8434\n",
            "[  331] accuracy =     0.8415\n",
            "[  332] accuracy =     0.8403\n",
            "[  333] accuracy =     0.8392\n",
            "[  334] accuracy =      0.841\n",
            "[  335] accuracy =     0.8431\n",
            "[  336] accuracy =     0.8452\n",
            "[  337] accuracy =     0.8425\n",
            "[  338] accuracy =     0.8426\n",
            "[  339] accuracy =     0.8419\n",
            "[  340] accuracy =     0.8427\n",
            "[  341] accuracy =     0.8405\n",
            "[  342] accuracy =     0.8382\n",
            "[  343] accuracy =     0.8387\n",
            "[  344] accuracy =     0.8388\n",
            "[  345] accuracy =     0.8377\n",
            "[  346] accuracy =      0.841\n",
            "[  347] accuracy =     0.8415\n",
            "[  348] accuracy =     0.8442\n",
            "[  349] accuracy =      0.844\n",
            "[  350] accuracy =     0.8423\n",
            "[  351] accuracy =     0.8436\n",
            "[  352] accuracy =     0.8443\n",
            "[  353] accuracy =     0.8453\n",
            "[  354] accuracy =     0.8437\n",
            "[  355] accuracy =     0.8467\n",
            "[  356] accuracy =     0.8449\n",
            "[  357] accuracy =     0.8453\n",
            "[  358] accuracy =     0.8484\n",
            "[  359] accuracy =     0.8453\n",
            "[  360] accuracy =     0.8461\n",
            "[  361] accuracy =     0.8475\n",
            "[  362] accuracy =     0.8479\n",
            "[  363] accuracy =     0.8459\n",
            "[  364] accuracy =     0.8445\n",
            "[  365] accuracy =     0.8435\n",
            "[  366] accuracy =     0.8417\n",
            "[  367] accuracy =     0.8444\n",
            "[  368] accuracy =     0.8439\n",
            "[  369] accuracy =     0.8436\n",
            "[  370] accuracy =     0.8485\n",
            "[  371] accuracy =     0.8493\n",
            "[  372] accuracy =     0.8504\n",
            "[  373] accuracy =     0.8478\n",
            "[  374] accuracy =     0.8478\n",
            "[  375] accuracy =     0.8486\n",
            "[  376] accuracy =     0.8499\n",
            "[  377] accuracy =     0.8506\n",
            "[  378] accuracy =     0.8502\n",
            "[  379] accuracy =     0.8471\n",
            "[  380] accuracy =     0.8486\n",
            "[  381] accuracy =     0.8497\n",
            "[  382] accuracy =       0.85\n",
            "[  383] accuracy =     0.8489\n",
            "[  384] accuracy =     0.8514\n",
            "[  385] accuracy =     0.8511\n",
            "[  386] accuracy =     0.8442\n",
            "[  387] accuracy =     0.8465\n",
            "[  388] accuracy =     0.8468\n",
            "[  389] accuracy =     0.8498\n",
            "[  390] accuracy =     0.8496\n",
            "[  391] accuracy =     0.8478\n",
            "[  392] accuracy =     0.8479\n",
            "[  393] accuracy =     0.8503\n",
            "[  394] accuracy =     0.8465\n",
            "[  395] accuracy =      0.847\n",
            "[  396] accuracy =     0.8475\n",
            "[  397] accuracy =     0.8475\n",
            "[  398] accuracy =     0.8492\n",
            "[  399] accuracy =     0.8489\n",
            "[  400] accuracy =     0.8508\n",
            "[  401] accuracy =     0.8512\n",
            "[  402] accuracy =     0.8514\n",
            "[  403] accuracy =     0.8521\n",
            "[  404] accuracy =     0.8531\n",
            "[  405] accuracy =     0.8521\n",
            "[  406] accuracy =     0.8522\n",
            "[  407] accuracy =     0.8531\n",
            "[  408] accuracy =      0.852\n",
            "[  409] accuracy =     0.8521\n",
            "[  410] accuracy =     0.8519\n",
            "[  411] accuracy =     0.8515\n",
            "[  412] accuracy =      0.851\n",
            "[  413] accuracy =     0.8518\n",
            "[  414] accuracy =      0.853\n",
            "[  415] accuracy =      0.854\n",
            "[  416] accuracy =     0.8531\n",
            "[  417] accuracy =     0.8517\n",
            "[  418] accuracy =     0.8513\n",
            "[  419] accuracy =     0.8518\n",
            "[  420] accuracy =     0.8538\n",
            "[  421] accuracy =     0.8567\n",
            "[  422] accuracy =     0.8531\n",
            "[  423] accuracy =     0.8521\n",
            "[  424] accuracy =     0.8528\n",
            "[  425] accuracy =     0.8547\n",
            "[  426] accuracy =     0.8537\n",
            "[  427] accuracy =     0.8534\n",
            "[  428] accuracy =     0.8551\n",
            "[  429] accuracy =     0.8548\n",
            "[  430] accuracy =     0.8546\n",
            "[  431] accuracy =     0.8549\n",
            "[  432] accuracy =     0.8538\n",
            "[  433] accuracy =     0.8505\n",
            "[  434] accuracy =     0.8514\n",
            "[  435] accuracy =      0.854\n",
            "[  436] accuracy =     0.8563\n",
            "[  437] accuracy =     0.8531\n",
            "[  438] accuracy =     0.8529\n",
            "[  439] accuracy =     0.8555\n",
            "[  440] accuracy =     0.8549\n",
            "[  441] accuracy =     0.8551\n",
            "[  442] accuracy =     0.8568\n",
            "[  443] accuracy =     0.8559\n",
            "[  444] accuracy =     0.8542\n",
            "[  445] accuracy =     0.8531\n",
            "[  446] accuracy =     0.8525\n",
            "[  447] accuracy =     0.8525\n",
            "[  448] accuracy =     0.8512\n",
            "[  449] accuracy =     0.8541\n",
            "[  450] accuracy =     0.8526\n",
            "[  451] accuracy =     0.8539\n",
            "[  452] accuracy =     0.8535\n",
            "[  453] accuracy =     0.8545\n",
            "[  454] accuracy =     0.8588\n",
            "[  455] accuracy =      0.856\n",
            "[  456] accuracy =     0.8566\n",
            "[  457] accuracy =     0.8564\n",
            "[  458] accuracy =     0.8536\n",
            "[  459] accuracy =     0.8561\n",
            "[  460] accuracy =      0.857\n",
            "[  461] accuracy =     0.8592\n",
            "[  462] accuracy =      0.855\n",
            "[  463] accuracy =     0.8569\n",
            "[  464] accuracy =     0.8586\n",
            "[  465] accuracy =      0.859\n",
            "[  466] accuracy =     0.8582\n",
            "[  467] accuracy =     0.8581\n",
            "[  468] accuracy =     0.8575\n",
            "[  469] accuracy =     0.8588\n",
            "[  470] accuracy =     0.8574\n",
            "[  471] accuracy =     0.8573\n",
            "[  472] accuracy =     0.8585\n",
            "[  473] accuracy =     0.8583\n",
            "[  474] accuracy =     0.8612\n",
            "[  475] accuracy =     0.8603\n",
            "[  476] accuracy =     0.8605\n",
            "[  477] accuracy =     0.8559\n",
            "[  478] accuracy =     0.8596\n",
            "[  479] accuracy =     0.8616\n",
            "[  480] accuracy =     0.8616\n",
            "[  481] accuracy =     0.8605\n",
            "[  482] accuracy =     0.8591\n",
            "[  483] accuracy =     0.8561\n",
            "[  484] accuracy =      0.858\n",
            "[  485] accuracy =       0.86\n",
            "[  486] accuracy =     0.8607\n",
            "[  487] accuracy =     0.8611\n",
            "[  488] accuracy =     0.8618\n",
            "[  489] accuracy =     0.8604\n",
            "[  490] accuracy =     0.8622\n",
            "[  491] accuracy =     0.8607\n",
            "[  492] accuracy =     0.8632\n",
            "[  493] accuracy =     0.8629\n",
            "[  494] accuracy =      0.862\n",
            "[  495] accuracy =     0.8615\n",
            "[  496] accuracy =     0.8631\n",
            "[  497] accuracy =     0.8578\n",
            "[  498] accuracy =     0.8565\n",
            "[  499] accuracy =     0.8566\n",
            "[  500] accuracy =     0.8548\n",
            "[  501] accuracy =     0.8567\n",
            "[  502] accuracy =     0.8568\n",
            "[  503] accuracy =     0.8584\n",
            "[  504] accuracy =     0.8578\n",
            "[  505] accuracy =     0.8582\n",
            "[  506] accuracy =     0.8599\n",
            "[  507] accuracy =     0.8596\n",
            "[  508] accuracy =     0.8594\n",
            "[  509] accuracy =      0.861\n",
            "[  510] accuracy =     0.8606\n",
            "[  511] accuracy =     0.8612\n",
            "[  512] accuracy =     0.8633\n",
            "[  513] accuracy =     0.8626\n",
            "[  514] accuracy =     0.8629\n",
            "[  515] accuracy =     0.8621\n",
            "[  516] accuracy =     0.8616\n",
            "[  517] accuracy =     0.8603\n",
            "[  518] accuracy =     0.8607\n",
            "[  519] accuracy =     0.8614\n",
            "[  520] accuracy =     0.8603\n",
            "[  521] accuracy =     0.8608\n",
            "[  522] accuracy =     0.8571\n",
            "[  523] accuracy =      0.856\n",
            "[  524] accuracy =     0.8601\n",
            "[  525] accuracy =     0.8611\n",
            "[  526] accuracy =     0.8533\n",
            "[  527] accuracy =     0.8516\n",
            "[  528] accuracy =     0.8571\n",
            "[  529] accuracy =     0.8546\n",
            "[  530] accuracy =     0.8575\n",
            "[  531] accuracy =     0.8565\n",
            "[  532] accuracy =     0.8575\n",
            "[  533] accuracy =     0.8592\n",
            "[  534] accuracy =     0.8623\n",
            "[  535] accuracy =     0.8619\n",
            "[  536] accuracy =     0.8607\n",
            "[  537] accuracy =      0.862\n",
            "[  538] accuracy =     0.8604\n",
            "[  539] accuracy =     0.8607\n",
            "[  540] accuracy =     0.8625\n",
            "[  541] accuracy =     0.8614\n",
            "[  542] accuracy =     0.8628\n",
            "[  543] accuracy =     0.8613\n",
            "[  544] accuracy =     0.8627\n",
            "[  545] accuracy =     0.8647\n",
            "[  546] accuracy =     0.8631\n",
            "[  547] accuracy =     0.8624\n",
            "[  548] accuracy =     0.8627\n",
            "[  549] accuracy =     0.8638\n",
            "[  550] accuracy =     0.8639\n",
            "[  551] accuracy =     0.8626\n",
            "[  552] accuracy =     0.8645\n",
            "[  553] accuracy =     0.8643\n",
            "[  554] accuracy =     0.8639\n",
            "[  555] accuracy =      0.865\n",
            "[  556] accuracy =     0.8632\n",
            "[  557] accuracy =     0.8634\n",
            "[  558] accuracy =     0.8634\n",
            "[  559] accuracy =     0.8607\n",
            "[  560] accuracy =     0.8636\n",
            "[  561] accuracy =     0.8631\n",
            "[  562] accuracy =     0.8642\n",
            "[  563] accuracy =     0.8654\n",
            "[  564] accuracy =     0.8658\n",
            "[  565] accuracy =     0.8641\n",
            "[  566] accuracy =      0.863\n",
            "[  567] accuracy =     0.8639\n",
            "[  568] accuracy =     0.8625\n",
            "[  569] accuracy =     0.8655\n",
            "[  570] accuracy =     0.8634\n",
            "[  571] accuracy =     0.8621\n",
            "[  572] accuracy =      0.863\n",
            "[  573] accuracy =      0.862\n",
            "[  574] accuracy =     0.8658\n",
            "[  575] accuracy =     0.8648\n",
            "[  576] accuracy =      0.866\n",
            "[  577] accuracy =     0.8636\n",
            "[  578] accuracy =     0.8639\n",
            "[  579] accuracy =     0.8621\n",
            "[  580] accuracy =     0.8593\n",
            "[  581] accuracy =     0.8611\n",
            "[  582] accuracy =     0.8615\n",
            "[  583] accuracy =     0.8618\n",
            "[  584] accuracy =     0.8618\n",
            "[  585] accuracy =     0.8618\n",
            "[  586] accuracy =     0.8615\n",
            "[  587] accuracy =     0.8623\n",
            "[  588] accuracy =     0.8616\n",
            "[  589] accuracy =     0.8605\n",
            "[  590] accuracy =     0.8606\n",
            "[  591] accuracy =     0.8611\n",
            "[  592] accuracy =     0.8615\n",
            "[  593] accuracy =     0.8621\n",
            "[  594] accuracy =     0.8624\n",
            "[  595] accuracy =     0.8629\n",
            "[  596] accuracy =     0.8634\n",
            "[  597] accuracy =     0.8643\n",
            "[  598] accuracy =      0.863\n",
            "[  599] accuracy =     0.8622\n",
            "[  600] accuracy =     0.8651\n",
            "[  601] accuracy =     0.8668\n",
            "[  602] accuracy =     0.8653\n",
            "[  603] accuracy =     0.8625\n",
            "[  604] accuracy =     0.8651\n",
            "[  605] accuracy =     0.8646\n",
            "[  606] accuracy =     0.8666\n",
            "[  607] accuracy =     0.8697\n",
            "[  608] accuracy =     0.8671\n",
            "[  609] accuracy =     0.8666\n",
            "[  610] accuracy =      0.867\n",
            "[  611] accuracy =     0.8668\n",
            "[  612] accuracy =     0.8663\n",
            "[  613] accuracy =     0.8655\n",
            "[  614] accuracy =     0.8661\n",
            "[  615] accuracy =     0.8652\n",
            "[  616] accuracy =     0.8662\n",
            "[  617] accuracy =     0.8675\n",
            "[  618] accuracy =     0.8672\n",
            "[  619] accuracy =     0.8678\n",
            "[  620] accuracy =     0.8689\n",
            "[  621] accuracy =     0.8687\n",
            "[  622] accuracy =     0.8676\n",
            "[  623] accuracy =     0.8653\n",
            "[  624] accuracy =     0.8652\n",
            "[  625] accuracy =      0.864\n",
            "[  626] accuracy =     0.8659\n",
            "[  627] accuracy =     0.8689\n",
            "[  628] accuracy =     0.8676\n",
            "[  629] accuracy =     0.8665\n",
            "[  630] accuracy =     0.8681\n",
            "[  631] accuracy =     0.8675\n",
            "[  632] accuracy =     0.8675\n",
            "[  633] accuracy =     0.8676\n",
            "[  634] accuracy =     0.8681\n",
            "[  635] accuracy =     0.8677\n",
            "[  636] accuracy =     0.8706\n",
            "[  637] accuracy =     0.8675\n",
            "[  638] accuracy =     0.8673\n",
            "[  639] accuracy =     0.8688\n",
            "[  640] accuracy =      0.869\n",
            "[  641] accuracy =     0.8686\n",
            "[  642] accuracy =     0.8671\n",
            "[  643] accuracy =     0.8641\n",
            "[  644] accuracy =     0.8644\n",
            "[  645] accuracy =     0.8648\n",
            "[  646] accuracy =      0.866\n",
            "[  647] accuracy =     0.8663\n",
            "[  648] accuracy =     0.8685\n",
            "[  649] accuracy =     0.8684\n",
            "[  650] accuracy =      0.863\n",
            "[  651] accuracy =     0.8654\n",
            "[  652] accuracy =      0.868\n",
            "[  653] accuracy =     0.8661\n",
            "[  654] accuracy =     0.8702\n",
            "[  655] accuracy =     0.8687\n",
            "[  656] accuracy =     0.8707\n",
            "[  657] accuracy =     0.8679\n",
            "[  658] accuracy =     0.8688\n",
            "[  659] accuracy =     0.8669\n",
            "[  660] accuracy =     0.8665\n",
            "[  661] accuracy =     0.8661\n",
            "[  662] accuracy =     0.8684\n",
            "[  663] accuracy =     0.8686\n",
            "[  664] accuracy =     0.8696\n",
            "[  665] accuracy =     0.8691\n",
            "[  666] accuracy =     0.8695\n",
            "[  667] accuracy =     0.8697\n",
            "[  668] accuracy =     0.8677\n",
            "[  669] accuracy =     0.8696\n",
            "[  670] accuracy =     0.8678\n",
            "[  671] accuracy =     0.8679\n",
            "[  672] accuracy =     0.8695\n",
            "[  673] accuracy =     0.8676\n",
            "[  674] accuracy =     0.8677\n",
            "[  675] accuracy =     0.8685\n",
            "[  676] accuracy =     0.8634\n",
            "[  677] accuracy =     0.8671\n",
            "[  678] accuracy =     0.8678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9088bb02c06a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'for epoch_idx in range(1, N_epoch+1):\\n    np.random.shuffle(train_data_idx)\\n    for batch_idx in range(batch_count):\\n        batch_data = np.array([train_data[train_data_idx[idx]] for idx in range(batch_size)])\\n        batch_labels = np.array([train_labels[train_data_idx[idx]] for idx in range(batch_size)])\\n        sess.run(train, feed_dict={x_ph: batch_data, labels_ph: batch_labels})\\n    if epoch_idx%1 == 0:\\n        y_out = sess.run(hypothesis, feed_dict={x_ph: test_data})\\n        accu = Accuracy(y_out,test_labels)\\n        print(\"[{:>5}] accuracy = {:>10.4}\".format(epoch_idx,accu))\\n        arr_epoch.append(epoch_idx)\\n        arr_accu.append(accu)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFnQH9uDgQjA",
        "colab_type": "text"
      },
      "source": [
        "> ### Ploting : Cost/Training Count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA_PjWijgQZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot : Accuracy / Epoch\n",
        "fig_accu, ax_accu = plt.subplots()\n",
        "ax_accu.plot(arr_epoch, arr_accu)\n",
        "ax_accu.set_title(\"Accuracy / Epoch (SLP)\")\n",
        "ax_accu.grid(True)\n",
        "ax_accu.set_ylim(0,1.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGGEVBPcTyUa",
        "colab_type": "text"
      },
      "source": [
        "> ### Training 이후"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x-EJKJhTzqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_out = sess.run(hypothesis, feed_dict={x_ph: test_data})\n",
        "y_max = np.argmax(y_out, axis=1).reshape((-1, 1))\n",
        "Make_Result_Plot(\"After Training\", test_data, test_labels, y_max)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGheYT3bv91S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}