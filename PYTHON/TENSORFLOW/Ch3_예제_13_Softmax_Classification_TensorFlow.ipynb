{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch3_예제_13_Softmax_Classification_TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KwonYN/TIL/blob/master/PYTHON/TENSORFLOW/Ch3_%EC%98%88%EC%A0%9C_13_Softmax_Classification_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERQax80Nl2fY",
        "colab_type": "text"
      },
      "source": [
        "# Chapter3-4. Deep Learning 기초 : Softmax Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvu8nWycl9Qp",
        "colab_type": "text"
      },
      "source": [
        ">## [예제3-13] Softmax Classification (TensorFlow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba-LxKfLmGVu",
        "colab_type": "text"
      },
      "source": [
        ">### Load modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXxAYyqxlNxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "80c23abd-b555-4c80-d7f7-36e803c721b4"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Module Loaded.\")\n",
        "print(\"NumPy Version :{}\".format(np.__version__))\n",
        "print(\"TensorFlow Version :{}\".format(tf.__version__))\n",
        "print(\"Matplotlib Version :{}\".format(plt.matplotlib.__version__))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Module Loaded.\n",
            "NumPy Version :1.17.4\n",
            "TensorFlow Version :1.15.0\n",
            "Matplotlib Version :3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tdKm3VimauR",
        "colab_type": "text"
      },
      "source": [
        "> ### Input and Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMhaNhF0mIXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_input = np.array([ [1, 1],  [2, 2.5],  [2.5, 1.3],  [4.3, 9.5],  [5.5, 7.0], [6, 8.2],   [7, 5],    [8, 6],   [9, 4.5]], dtype=np.float)\n",
        "if 1:\n",
        "  labels = np.array([[1, 0, 0], [1, 0, 0], [1, 0, 0],   [0, 1, 0],   [0, 1, 0],  [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1]], dtype=np.float)\n",
        "else: # 다시..\n",
        "  labels_tmp = np.array( [0, 0, 0, 1, 1, 1, 2, 2, 2] )\n",
        "  labels = tf.one_hot(labels_tmp, depth=3, on_value=True, off_value=False, dtype=float32).eval()\n",
        "  print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgFlDyu-mgHN",
        "colab_type": "text"
      },
      "source": [
        "> ### Placeholder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vse7W7x7mh8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_var = 2\n",
        "n_class = 3\n",
        "\n",
        "x_ph = tf.placeholder(tf.float32, (None, n_var), name=\"input\")\n",
        "labels_ph = tf.placeholder(tf.float32, (None, n_class), name=\"labels\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7v1V11kmrRz",
        "colab_type": "text"
      },
      "source": [
        ">### Activation Function : Softmax Function\n",
        ">$S(y_{i}) = \\frac{e^{y_{i}}}{\\sum_{j=0}^{m-1}e^{y_{j}}}$\n",
        ">## Hypothesis\n",
        ">## $H(X) = S(XW+B)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gk1hqtjmhyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = tf.Variable(tf.random.normal((n_var, n_class)), dtype=tf.float32, name=\"weight\")\n",
        "B = tf.Variable(tf.random.normal((1, n_class)), dtype=tf.float32, name=\"bias\")\n",
        "\n",
        "logits = tf.matmul(x_ph, W) + B\n",
        "hypothesis = tf.nn.softmax(logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seBAAuk9nHMR",
        "colab_type": "text"
      },
      "source": [
        ">## Cost Function : Cross Entropy Error\n",
        ">## $cost(W,b) = -\\sum_{i=1}^{m}p_{i}\\log_{2}q_{i}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHC4LL4unD6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cost = tf.reduce_mean(-tf.reduce_sum(labels_ph * tf.log(hypothesis), axis=1)) \n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels_ph))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXzJJ2QbnMjI",
        "colab_type": "text"
      },
      "source": [
        ">### Optimizer : tf.train.GradientDescentOptimizer (Gradient Descent Optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNI3OBVCnM_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "train = optimizer.minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXTYroJlnZzc",
        "colab_type": "text"
      },
      "source": [
        ">### 학습 준비 과정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1mBO7zSnaVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_training = 100000\n",
        "training_idx = np.arange(0, N_training+1, 1)\n",
        "cost_graph = np.zeros(N_training+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dhfsRZQnm-C",
        "colab_type": "text"
      },
      "source": [
        "### 학습 (Training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-3I0oV_nnYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77f4477f-3d38-4d81-9560-6ae466d9c12b"
      },
      "source": [
        "# 학습 (Training)\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "cost_graph[0] = sess.run((cost), feed_dict={x_ph: x_input, labels_ph: labels})\n",
        "print(\"[{:>5}] cost = {:>10.4}\".format(0, cost_graph[0]))\n",
        "for cnt_training in range(1, N_training+1):\n",
        "    cost_res, _ = sess.run((cost, train), feed_dict={x_ph: x_input, labels_ph: labels})\n",
        "    cost_graph[cnt_training] = cost_res\n",
        "    if cnt_training % 1000 == 0:\n",
        "        print(\"[{:>5}] cost = {:>10.4}\".format(cnt_training, cost_graph[cnt_training]))\n",
        "\n",
        "\n",
        "\n",
        "print(np.argmax(sess.run(hypothesis, feed_dict={x_ph:x_input}), axis=1))\n",
        "\n",
        "x_test = np.array([[5.5, 5], [4.7, 10.0], [9, 3.1]])\n",
        "print(np.argmax(sess.run(hypothesis, feed_dict={x_ph:x_test}), axis=1))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0] cost =      9.663\n",
            "[ 1000] cost =     0.3549\n",
            "[ 2000] cost =     0.1778\n",
            "[ 3000] cost =     0.1145\n",
            "[ 4000] cost =    0.08381\n",
            "[ 5000] cost =    0.06595\n",
            "[ 6000] cost =    0.05433\n",
            "[ 7000] cost =    0.04619\n",
            "[ 8000] cost =    0.04017\n",
            "[ 9000] cost =    0.03555\n",
            "[10000] cost =    0.03188\n",
            "[11000] cost =    0.02891\n",
            "[12000] cost =    0.02644\n",
            "[13000] cost =    0.02437\n",
            "[14000] cost =     0.0226\n",
            "[15000] cost =    0.02107\n",
            "[16000] cost =    0.01974\n",
            "[17000] cost =    0.01857\n",
            "[18000] cost =    0.01753\n",
            "[19000] cost =     0.0166\n",
            "[20000] cost =    0.01577\n",
            "[21000] cost =    0.01502\n",
            "[22000] cost =    0.01433\n",
            "[23000] cost =    0.01371\n",
            "[24000] cost =    0.01314\n",
            "[25000] cost =    0.01262\n",
            "[26000] cost =    0.01213\n",
            "[27000] cost =    0.01168\n",
            "[28000] cost =    0.01127\n",
            "[29000] cost =    0.01088\n",
            "[30000] cost =    0.01052\n",
            "[31000] cost =    0.01019\n",
            "[32000] cost =   0.009869\n",
            "[33000] cost =   0.009573\n",
            "[34000] cost =   0.009293\n",
            "[35000] cost =    0.00903\n",
            "[36000] cost =   0.008782\n",
            "[37000] cost =   0.008547\n",
            "[38000] cost =   0.008324\n",
            "[39000] cost =   0.008113\n",
            "[40000] cost =   0.007913\n",
            "[41000] cost =   0.007722\n",
            "[42000] cost =    0.00754\n",
            "[43000] cost =   0.007367\n",
            "[44000] cost =   0.007202\n",
            "[45000] cost =   0.007044\n",
            "[46000] cost =   0.006893\n",
            "[47000] cost =   0.006748\n",
            "[48000] cost =   0.006609\n",
            "[49000] cost =   0.006476\n",
            "[50000] cost =   0.006349\n",
            "[51000] cost =   0.006226\n",
            "[52000] cost =   0.006108\n",
            "[53000] cost =   0.005994\n",
            "[54000] cost =   0.005885\n",
            "[55000] cost =    0.00578\n",
            "[56000] cost =   0.005678\n",
            "[57000] cost =    0.00558\n",
            "[58000] cost =   0.005485\n",
            "[59000] cost =   0.005394\n",
            "[60000] cost =   0.005305\n",
            "[61000] cost =    0.00522\n",
            "[62000] cost =   0.005137\n",
            "[63000] cost =   0.005057\n",
            "[64000] cost =   0.004979\n",
            "[65000] cost =   0.004904\n",
            "[66000] cost =   0.004831\n",
            "[67000] cost =    0.00476\n",
            "[68000] cost =   0.004691\n",
            "[69000] cost =   0.004624\n",
            "[70000] cost =   0.004559\n",
            "[71000] cost =   0.004496\n",
            "[72000] cost =   0.004435\n",
            "[73000] cost =   0.004375\n",
            "[74000] cost =   0.004317\n",
            "[75000] cost =    0.00426\n",
            "[76000] cost =   0.004205\n",
            "[77000] cost =   0.004151\n",
            "[78000] cost =   0.004099\n",
            "[79000] cost =   0.004048\n",
            "[80000] cost =   0.003999\n",
            "[81000] cost =    0.00395\n",
            "[82000] cost =   0.003903\n",
            "[83000] cost =   0.003857\n",
            "[84000] cost =   0.003812\n",
            "[85000] cost =   0.003768\n",
            "[86000] cost =   0.003724\n",
            "[87000] cost =   0.003683\n",
            "[88000] cost =   0.003642\n",
            "[89000] cost =   0.003601\n",
            "[90000] cost =   0.003562\n",
            "[91000] cost =   0.003524\n",
            "[92000] cost =   0.003486\n",
            "[93000] cost =   0.003449\n",
            "[94000] cost =   0.003413\n",
            "[95000] cost =   0.003378\n",
            "[96000] cost =   0.003344\n",
            "[97000] cost =    0.00331\n",
            "[98000] cost =   0.003276\n",
            "[99000] cost =   0.003244\n",
            "[100000] cost =   0.003212\n",
            "[0 0 0 1 1 1 2 2 2]\n",
            "[2 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC4cFXOmnrGO",
        "colab_type": "text"
      },
      "source": [
        ">### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw6dWbzJnrXy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6838ac6c-43de-478d-e96e-b0fc1004d474"
      },
      "source": [
        "# Training 상황에 대한 그래프 출력\n",
        "# 1)Training 회수 별 Cost 값\n",
        "fig_cost, ax_cost = plt.subplots()\n",
        "ax_cost.plot(training_idx, cost_graph)\n",
        "ax_cost.set_title(\"'Cost / Training Count' Graph\")\n",
        "ax_cost.set_xlabel(\"Train Count\")\n",
        "ax_cost.set_ylabel(\"Cost\")\n",
        "ax_cost.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAXVljVTP2JQzAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OANItE0Aj9xi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}